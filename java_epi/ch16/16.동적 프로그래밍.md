# 16장 동적 프로그래밍

동적 프로그래밍은 부분 문제로 분해할 수 있는 최적화, 탐색, 계산 문제를 해결하기 위한 일반적인 방법을 말한다. 해법에 도달하기 위해 선택을 해야할 때마다 (특히 해법이 부분 문제와 관련이 있는 경우) 동적 프로그래밍을 고려해 봐야 한다.

분할 정복법처럼 동적 프로그래밍은 작은 문제 여러 개를 합쳐서 큰 문제를 풀 수 있다. 하지만 분할 정복과는 다르게, 동적 프로그래밍에서는 동일한 하위 문제가 반복해서 발생할 수 있다. 따라서 동적 프로그래밍을 효율적으로 작성하려면 반복해서 발생하는 하위 문제의 결괏값을 캐싱(caching)해 두어야 한다. 면접에서는 어려운 문제를 출제하려고 할 때, 동적 프로그래밍 문제를 선택하는 경향이 있다.

우선 피보나치 수열을 구하는 문제를 통해 동적 프로그래밍의 기본 개념을 살펴보자. 피보나치 수열은 0,1로 시작한다. 그 다음 숫자는 이전 숫자 두 개의 합이다. 따라서 0,1,1,2,3,5,8,13,21,...이 된다. 이 수열은 생물학, 자료구조 분석, 병렬 컴퓨팅 등 다양한 애플리케이션에서 활용된다.

수학적으로 표현하자면 n번째 피보나치 수열은 $F(n) = F(n-1) + F(n-2)$이고, $F(0) = 0, F(1) = 1$이다. 이때 $F(n)$을 재귀적으로 계산하는 함수의 시간 복잡도는 기하급수적으로 증가한다. 왜냐하면 재귀 함수가 F(i)를 반복적으로 호출하기 때문이다. 그림 16.1을 보면 같은 함수가 어떻게 반복적으로 호출되는지 알 수 있다.

중간 결과를 캐시에 저장했을 때 n번째 피보나치 수열을 구하는 시간 복잡도는 n에 선형적으로 비례하지만, 추가적인 공간 복잡도는 $O(n)$이 된다.

```java
private static Map<Integer, Integer> cache = new HashMap<>();

public static int fibonacci(int n) {
    if (n <= 1) {
        return n;
    } else if (!cache.containsKey(n)) {
        cache.put(n, fibonacci(n - 2) + fibonacci(n - 1));
    }
    return cache.get(n);
}
```

캐시 공간을 최소화하는 것은 동적 프로그래밍에서 중요한 이슈이다. 이번에는 같은 프로그램을 $O(n)$ 시간과 $O(1)$ 공간에 구해 보자. 다음 코드는 앞에서 살펴본 프로그램과 개념적으로는 반대다. 상향식 방식으로 캐시를 반복적으로 채워 공간 복잡성을 줄이고, 캐시를 재사용할 수 있게 한다.

```java
public static int fibonacci(int n) {
    if (n <= 1) {
        return n;
    }

    int fMinus2 = 0;
    int fMinus1 = 1;
    for (int i = 2; i <= n; i++) {
        int f = fMinus2 + fMinus1;
        fMinus2 = fMinus1;
        fMinus1 = f;
    }
    return fMinus1;
}
```

동적 프로그래밍을 효율적으로 푸는 핵심은 하나의 문제를 부분 문제로 나누는 방법을 찾는다. 부분 문제는 다음과 같은 특징이 있다. 이 특징을 잘 이용하면 부분 문제를 쉽게 찾을 수 있다.

- 부분 문제의 해법을 찾으면 원래 문제도 비교적 쉽게 해결할 수 있다.
- 부분 문제의 해법을 캐시에 저장할 수 있다.

이번에는 좀 더 복잡한 문제를 다루어 보자. 정수 배열이 주어졌을 때 합이 가장 큰 부분배열을 동적 프로그래밍으로 구하라. 그림 16.2의 배열이 주어졌을 때 합이 최대가 되는 부분배열은 0번 인덱스에서 3번 인덱스까지다.

```text
    904, 40, 523, 12, -335, -385, -124, 481, -31
    A[0],A[1],A[2],A[3],A[4],A[5],A[6],A[7],A[8]
```

모든 부분배열의 합을 구해야 하므로 무식하게 풀면 시간 복잡도가 $O(n^3)$이 된다. 부분배열의 개수는 $\frac{n(n-1)}{2}$이고, 각 부분배열의 합을 구하는 데 $O(n)$의 시간이 걸리기 때문이다. 하지만 추가로 $O(n)$의 공간을 사용해서 모든 k에 대한 $S[k] = \sum{A[0,k]}$를 저장할 수 있다면, 무식한 방법의 시간 복잡도를 $O(n^2)$으로 개선할 수 있다. $A[i,j]$의 합은 $S[j] - S[i - 1]$이고, $S[-1]$은 0이 된다.

분할 정복법으로도 이 문제를 풀 수 있다. 먼저 A의 중간 인덱스인 $m = \lfloor\frac{n}{2}\rfloor$을 구한다. 부분배열 $L = A[0,m]$과 $R = A[m + 1, n - 1]$에 대해서 같은 문제를 푼다. 각각의 최댓값을 구하는 것 외에도 L 배열의 인덱스 m에서 끝나는 부분배열의 최대합 l과 R 배열의 첫 인덱스에서 시작하는 부분배열의 최대합 r 또한 구해야 한다. A의 최대 부부배열합은 l + r, L의 최대합, R의 최대합 중에 큰 값이 된다. 시간 복잡도는 $O(n log n)$이며, 퀵정렬의 시간 복잡도를 분석하는 방법과 비슷하게 구할 수 있다. 인덱스를 다루는 작업이 까다로워 프로그램을 올바르게 작성하는 데 시간이 걸릴 것이다.

이제 동적 프로그래밍을 사용해서 문제를 풀어 보자. 부분배열 $A[0, n-2]$의 해법을 알고 있다고 가정하고 문제를 푸는 것에서 시작하고 싶을 것이다. 그런데 부분배열 $A[0, n-2]$의 최대부분합을 알고 있다고 하더라도 $A[0, n-1]$의 해법을 구하는 데 도움이 되지 않는다. i < n - 1의 모든 부분배열 A[0,i]에 대해서 가장 작은 부분배열의 합을 알고 있어야 도움이 된다. 이 정보를 알고 있으면 S[n-1]에서 부분배열의 합을 뺀 값 중에 최댓값이 정답이 되기 때문이다. 다시 말해 j로 끝나는 최대부분합은 $S[j] - \min_{k \le j}S[k]$가 된다. 배열을 차례대로 순회할 때마다 합이 가장 작은 S[k]를 추적할 수 있으므로 각 인덱스에 대한 최대 부분합을 찾을 수 있다. 각 인덱스에서 최대 부분합을 구하는 데 상수 시간이 걸리므로 시간 복잡도는 $O(n)$이고 공간 복잡도는 $O(1)$이 된다. 모든 배열의 값이 음수일 수도 있고 배열이 비어 있을 수도 있기 때문에, 이런 경우의 입력도 처리할 수 있어야 한다.

```java
public static int findMaximumSubarray(List<Integer> A) {
    int minSum = 0, sum = 0 maxSum = 0;
    for (int i = 0; i < A.size(); i++) {
        sum += A.get(i);
        if (sum < minSum) {
            minSum = sum;
        }
        if (sum - minSum > maxSum) {
            maxSum = sum - minSum;
        }
    }
    return maxSum;
}
```

## 동적 프로그래밍 부트 캠프

방금까지 살펴본 피보나치 수열과 최대 부분합을 구하는 문제는 동적 프로그래밍을 연습하기에 좋은 예제다.

- 문제가 부분 문제와 관련이 있는 경우에는 더더욱 동적 프로그래밍을 고려해 봐야 한다.
- 동적 프로그래밍은 최적화 문제뿐 아니라 **개수를 세는 문제, 의사 결정 문제**를 푸는 데도 쓸 수 있다. 동일한 계산을 재귀적으로 사용하는 작은 부분 문제들로 사용하는 작은 부분 문제들로 전체 문제를 표현할 수 있다면, 동적 프로그래밍으로 풀 수 있다.
- 이와 같은 개념으로 보자면, 동적 프로그래밍에는 재귀가 포함된다. 하지만 캐시는 효율성을 위해 **상향식**, 즉 반복적으로 구축되는 경우가 많다. [문제 16.3]
- 동적 프로그래밍이 재귀적으로 구현될 때, 캐시는 보통 해시 테이블이나 이진 탐색 트리 같은 동적 자료구조로 구현된다. 반복적으로 구현되는 캐시는 보통 1차원이나 다차원 배열이다.
- 공간을 절약하기 위해 다시 사용하지 않게 될 **캐시 공간**을 **재사용**할 수도 있다. [문제 16.1, 16.2]
- 가끔은 **상향식 동적 프로그래밍 해법보다 재귀가 더 효율적**일 때가 있다. 예를 들어 해법을 빨리 찾을 수 있거나 **가지치기**를 통해 탐색해야 할 부분 문제의 개수를 줄이는 경우다. [문제 16.5]
- 동적 프로그래밍은 부분 문제에 대한 **해법을 결합**하여 원래 문제에 대한 **해법을 제시**한다. 하지만 동적 프로그래밍으로 풀 수 없는 문제도 있다. 예를 들어 중간 도시를 반복해서 경유하지 않도록, 도시 1에서 도시 2까지 가는 가장 긴 경로를 구해야 한다고 하자. 이 경로는 도시 3을 통과한다. 이때 도시 1에서 도시 3으로, 그리고 도시 3에서 도시 2로 가는 각각의 하위 경로는, 문제에서 요구했던 '중간 도시를 반복해서 경유하지 않는 가장 긴 경로'가 아닐 수도 있다.

## 문제 16.1 가능한 점수가 몇 개인지 구하기

미국 미식축구는 각 게임당 2점(세이프티), 3점(필드골), 7점(터치다운, 추가점수)을 낼 수 있다. 시합이 끝난 후 획득한 점수를 모두 합한 결과가 최종 점수가 된다. 예를 들어 12점을 내는 방법은 다음과 같이 네 가지 경우의 수가 존재한다.

- 세이프티 6번(2 * 6 = 12)
- 세이프티 3번과 필드골 2번(2 * 3 + 3 * 2 = 12)
- 세이프티 1번과 필드골 1번, 터치다운 1번(2 * 1 + 3 * 1 + 7 * 1 = 12)
- 필드골 4번 (3 * 4 = 12)

최종 점수와 각 게임에서 낼 수 있는 점수가 주어졌을 때, 주어진 최종 점수를 만들 수 있는 조합의 개수를 반환하라.

> 힌트: 점수 $w0$을 0번 냈을 때, 점수 $w0$를 1번 냈을 때 등의 조합의 개수를 세어 보라.

낮은 점수를 통해 해법에 대한 감을 잡을 수 있다. 예를 들어 9점을 내는 경우는 다음과 같다.

- 7점을 낸 다음에 2점을 내기
- 6점을 낸 다음에 3점을 내기
- 2점을 낸 다음에 7점을 내기

이를 일반화해보면, s점수를 내는 방법은 s-2점을 낸 뒤에 2점을 내거나, s-3점을 낸 뒤에 3점을 내거나, s-7점을 낸 뒤에 7점을 내는 것이다. 이 방법을 통해 모든 가능한 점수의 수열을 재귀적으로 나열할 수 있다. 7점을 낸 뒤에 2점을 내도 9점이 되고, 2점을 낸 뒤에 7점을 내도 9점이 되므로 수열이 다르더라도 최종적으로 같은 점수를 만들 수 있다. 무식한 방법은 이 수열을 모두 나열한 뒤에 서로 다른 조합의 수열의 개수를 센다. 서로 다른 조합의 수열을 셀 때는 수열을 정렬하거나 해시 테이블을 사용할 수 있다.

수열의 개수가 굉장히 많을 것이므로 이 방법의 시간 복잡도는 굉장히 높다. 우리가 원하는 건 단지 조합의 개수일 뿐이므로 조합을 모두 구하지 않고도 답을 얻을 수 있는 방법을 생각해 보자.

예를 들어 최종 점수가 12점이고 각 경기에서 2점밖에 낼 수 없다면, 12점을 내는 방법은 한 가지뿐이다. 이제 각 경기에서 2점 혹은 3점을 낼 수 있다고 가정해 보자. 우리가 원하는 건 조합이므로 2점을 내는 경기는 3점을 내는 경기 전에 발생한다고 가정한다. 2점이 0번일 때 3점으로 12점을 만들 수 있는 경우의 수는 하나이다. 2점이 1번일 때 3점으로 12점을 만들 수 있는 경우의 수는 존재하지 않는다. (12 - 2는 3으로 나누어 떨어지지 않는다.) 2점이 2번일 때 3점으로 12점을 만들 수 있는 경우의 수는 존재하지 않는다. (12 - 2 * 2 또한 3으로 나누어 떨어지지 않는다.) 2점이 3번일 때 3점으로 12점을 만들 수 있는 경우의 수는 하나이다. (12 - 2 * 3은 3으로 나누어 떨어진다.) 여기에 7점을 추가해 보자. 그러면 2점과 3점의 경기로 12점을 만들거나 5점을 만드는 조합의 개수를 더해 주면 된다. (이들이 7점 경기를 추가했을 때 만들 수 있는 점수이다.)

예를 들어, 각 경기 점수가 W[0], W[1], ..., W[n-1]이고 최종 점수가 s라고 가정하자. 앞에서 설명한 고지식한 접근법은 동일한 문제를 반복적으로 해결하기 때문에 일반적으로 지수적인(exponential) 복잡성을 가진다.

이때 동적 프로그래밍을 사용하면 복잡도를 줄일 수 있다. 2차원 배열 A[i][j]에 W[0],W[1],...,W[i-1]의 조합으로 점수 j를 만들 수 있는 개수를 저장해 보자. 예를 들어 A[1][12]에는 2점과 3점으로 12점을 만들 수 있는 조합의 개수가 들어 있다. A[i+1],[j]는 단순하게 A[i][j] (즉, W[i+1]을 사용하지 않은 경우), A[i][j-W[i+1]] (W[i+1]을 한 번 사용한 경우), A[i][j-2W[i+1]] (W[i+1]을 두 번 사용한 경우) 등을 모두 더한 값이 된다.

이 알고리즘을 구하려면 3중 루프를 사용해야 한다. 첫 번째 반복문은 구하고자 하는 점수, 두 번째 반복문은 각 게임의 점수가 될 것이다. i와 j가 주어졌을 때, 세 번째 반복문은 j/W[i] + 1번 반복한다. (예를 들어 j=10, i=1, W[i]=3일 때, 세 번째 반복문은 A[0][10], A[0][7], A[0][4], A[0][1]의 값을 살펴본다.) 따라서 세 번째 반복문은 반복 횟수의 상한이 s와 같다. 따라서 전체 시간 복잡도는 $O(sns) = O(s^2n)$이 된다. (첫 번째 반복문이 n, 두 번째 반복문이 s, 세 번째 반복문의 상한은 s이다.)

A[i+1]의 행을 구하는 부분을 자세히 살펴보면, 좀 더 효율적으로 구할 수 있을 것 같다. 예를 들어 2점과 3점으로만 이루어진 게임을 생각해 보자. 2점 게임의 개수는 이미 구했다고 가정하자. 따라서 A[0]은 2점 게임의 결과를 포함한 행이 된다. 즉, A[0][j]는 2점으로 최종 점수 j를 만들 수 있는 조합의 개수이다. 여기에 3점 게임을 추가해서 최종 점수 12점을 만들 수 있는 조합의 개수는 A[0][0] + A[0][3] + A[0][6] + A[0][9] + A[0][12]와 같다. 2점과 3점 게임으로 최종 점수를 15점으로 만들 수 있는 조합의 개수는 A[0][0] + A[0][3] + A[0][6] + A[0][9] + A[0][12] + A[0][15]와 같다. 여기서 확실히 알 수 있는 건 A[0][0] + A[0][3] + A[0][6] + A[0][9] + A[0][12]를 다시 구하고 있다는 것이다. 이 점수는 최종 점수 12점을 구할 때 이미 계산했던 값이다.

A[1][15] = A[0][15] + A[1][12]와 같다. 이 점을 이용하면 A[1]의 행을 좀 더 효율적으로 구할 수 있다.
A[1][0] = A[0][0],
A[1][1] = A[0][1],
A[1][2] = A[0][2],
A[1][3] = A[0][3] + A[1][0],
A[1][4] = A[0][4] + A[1][1],
A[1][5] = A[0][5] + A[1][2],
...
이 되므로 A[1][i] = A[0][i] + A[1][i-3]과 같다. 따라서 A[1][i]를 구하는 데 $O(1)$의 시간이 걸린다. 그림 16.3의 표를 살펴보길 바란다.

다음은 이를 구현한 코드이다.

```java
public static int numCombinationsForFinalScore(int finalScore, List<Integer> individualPlayScores) {
    int[][] numCombinationsForScore = new int[individualPlayScores.size()][finalScore + 1];
    for (int i = 0; i < individualPlayScores.size(); i++) {
        numCombinationsForFinalScore[i][0] = 1; // 0점이 될 수 있는 방법의 개수
        for (int j = 1; j <= finalScore; j++) {
            int withoutThisPlay = i - 1 >= 0 ? numCombinationsForScore[i - 1][k] : 0;
            int withThisPlay = j >= individualPlayScores.get(i)
                                    ? numCombinationsForScore[i][j - individualPlayScores.get(i)]
                                    : 0;
            numCombinationsForScore[i][j] = withoutThisPlay + withThisPlay;
        }
    }
    return numCombinationsForScore[individualPlayScores.size() - 1][finalScore];
}
```

시간 복잡도는 $O(sn)$이다(하나는 s, 다른 하나는 n인 반복문 두 개). 공간 복잡도 또한 $O(sn)$이다(2차원 배열 크기).
