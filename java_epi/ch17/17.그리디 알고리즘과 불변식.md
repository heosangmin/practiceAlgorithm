# 17장 그리디 알고리즘과 불변식

```text
그리디 알고리즘

그리디 알고리즘은 해법을 단계적으로 계산한다. 각 단계마다 지역적으로(locally) 최적의 결정을 내리며, 이 결정은 절대 변경되지 않는다.
```

그리디 알고리즘이 늘 최적의 해법을 생성하는 것은 아니다. 과거 영국은 1,3,6,12,24,30펜스를 사용했다. 이 동전을 사용해서 48펜스틔 거스름돈을 만든다고 해보자. 동전의 수는 최소한으로 사용해야 한다. 자연스러운 그리디 알고리즘은 가장 액수가 큰 동전을 선택한 뒤 잔돈을 그보다 작거나 같은 동전을 반복해서 선택할 것이다. 48펜스를 만든다고 한다면 30 + 12 + 6, 이렇게 세 개의 동전을 사용할 것이다. 하지만 최적해법은 24펜스짜리 두 개의 동전을 이용하는 것이다.

일반적인 형태의 동전 교환 문제는 NP-난해(hard) 문제이다. 하지만 일부 동전 교환 문제는 그리디 알고리즘으로 풀 수 있다. 예를 들어 동전의 단가가 {1,r,$r^2$,$r^3$}인 경우이다. (미국 동전도 그리디 알고리즘으로 최적해를 구할 수 있다.) 일반적인 문제는 동적 프로그래밍을 사용해서 유사-다항(pseudo-polynomial) 시간에 풀 수 있는데, 문제 16.6과 비슷한 방법을 사용한다.

때로는 문제 대한 그리디 알고리즘이 여러 개 존재하면, 이들 중 일부만 최적의 해법을 제공하기도 한다. 예를 들어 2n의 도시가 한 줄로 늘어 서 있고, 이 중 절반은 흰색, 남은 절반은 검은색이라고 하자. 흰색 도시와 검은색 도시를 일대일 방식으로 짝지어서, 짝지어진 도시를 연결하는 데 필요한 도로 구간의 총 길이가 최소화되도록 해야 한다. 여러 쌍의 도시가 하나의 단일 구간을 공유할 수 있다. 예를 들어 (0,4)와 (1,2)를 짝지으면, 도시 0과 4 사이의 도로 구간을 도시 1과 2에서 사용할 수 있다.

이 문제에 대한 가장 단순한 그리디 알고리즘은 흰색 도시를 순회하면서, 각 흰색 도시와 가장 인접한 검은색 도시 중에 아직 짝이 없는 도시를 짝짓는 것이다. 하지만 이 알고리즘은 가장 최적의 해법이 아니다. 예를 들어 흰색 도시가 0과 3에 있고, 검은색 도시가 2와 5에 있다고 하자. 흰색 도시 3이 먼저 처리되면, 검은색 도시 2와 짝을 이룬다. 그러면 남아 있는 흰색 도시 0은 검은색 도시 5와 짝을 이루게 되므로, 도로 길이는 5가 된다. 반면에 도시 0과 2를 짝짓고, 3과 5를 짝지었다면 도로 길이는 4가 된다.

이렇게 보면, 약간 더 복잡한 그리디 알고리즘이 더 나은 결과를 가져온다. 모든 도시를 왼쪽에서 오른쪽 순서로 반복하면서, 아직 짝이 없는 다른 색깔의 도시와 짝짓는 것이다.

첫 번째 도시에 대한 짝은 최적의 해법이어야 한다. 만약 최적의 짝이 아닌 다른 도시와 짝지어지면, 도로를 추가할 필요가 없는 가장 가까운 검은색 도시와 짝을 이루도록 항상 변경될 수 있기 때문이다. 이러한 관찰은 전체적인 최적성의 귀납적 증거에 사용될 수 있다.

## 그리디 알고리즘 부트 캠프

미국 동전은 1,5,10,25,50,100 센트짜리가 있다. 그리디 알고리즘을 쓰면 최소 개수의 동전으로 필요한 거스름돈을 만들 수 있다. 다음은 이 알고리즘을 구현한 코드다. 특정 값의 동전 수를 한번 선택한 뒤에는, 절대 이 선택을 변경하지 않는 것이 그리디 알고리즘의 특징이다.

```java
public static int changeMaking(int cents) {
    final int[] CONIS = {100,50,25,10,5,1};
    int numCoins = 0;
    for (int i = 0; i < COINS.length; i++) {
        numCoins += cents / COINS[i];
        cents %= COINS[i];
    }
    return numCoins;
}
```

매번 일정한 양의 계산을 하고, 그 과정을 총 여섯 번 반복했으므로 시간 복잡도는 $O(1)$이 된다.

## 그리디 알고리즘 문제를 풀기 전 꼭 알고 있어야 할 내용

- 그리디 알고리즘은 보통, **각 단계에서 가장 최선의 선택**을 할 수 있는 **최적화 문제**에 적합한 선택이다. [문제 17.1]
- 그리디 알고리즘을 재귀적으로 추상화한 뒤에, 성능 향상을 위해 반복문을 써서 **구현**하면 더 쉬운 경우가 많다. [문제 24.31]
- 그리디 방법이 최적 해법을 찾지 못하더라도, 최적 알고리즘을 찾는 통찰력 혹은 휴리스틱에 대한 힌트가 될 수 있다.
- 때로는 어떤 그리디 알고리즘을 선택해야 올바른지 **명확하지 않은** 경우도 있다.

## 문제 17.1 최적의 업무 할당 구하기

노동자에게 업무를 할당하는 문제에 관해 생각해 보자. 각 노동자는 정확히 두 개의 업무를 할당받아야 한다. 각 업무를 완료하는 데 걸리는 시간은 고정되어 있으며, 각 업무는 서로 독립적이다. "3번 업무가 끝나기 전에 4번 업무를 수행할 수 없다"와 같은 제약사항은 없다. 누구나 어떤 업무든 할당받을 수 있다.

모든 업무를 완료하는 데 걸리는 시간이 최소가 되도록 노동자에게 업무를 할당해야 한다. 예를 들어 각각 5,2,1,6,4,4 시간이 걸리는 6개의 업무가 있을 때, 이를 최적으로 할당하는 방법은 처음 두 업무(5시간, 2시간짜리 업무)를 첫 번째 노동자에게 할당하고, 그 다음 두 업무(1시간, 6시간짜리 업무)를 두 번째 노동자에게 할당하고, 그 다음 두 업무(4시간, 4시간짜리 업무)를 세 번째 노동자에게 할당하는 것이다. 이렇게 하면, 모든 업무를 완료하는 데 걸리는 시간은 max(5 + 2, 1 + 6, 4 + 4) = 8시간이 된다.

업무 집합이 입력으로 주어졌을 때, 최적 할당을 반환하는 알고리즘을 설계하라.

> 힌트: 가장 오랜 시간이 걸리는 업무를 할당받은 노동자에게, 얼마만큼의 시간이 필요한 업무를 두 번째로 할당하는 것이 좋을까?

모든 가능한 업무의 쌍을 나열하는 방법은 실행 불가능하다. 그러한 쌍의 개수가 너무 많기 때문이다(n개의 업무가 있을 떄 정확히 $\binom{n}{2}\binom{n-2}{2}\binom{n-4}{2}...\binom{4}{2}\binom{2}{2} = n!/2^{n/2}$의 개수가 존재한다).

이 문제의 구조를 좀 더 자세히 살펴보자. 극단적인 값을 잘 처리하는 게 중요하다. 가장 오래 걸리는 일은 그만큼 많은 도움이 필요하다. 특히, 가장 오래 걸리는 업무를, 가장 빨리 끝낼 수 있는 업무와 쌍으로 묶는 것이 타당해 보인다. 이 사실은 가장 오래 걸리는 업무를 그 외의 업무와 쌍을 이루도록 할당했을 때와 비교해보면 알 수 있다. 가장 긴 시간이 걸리는 업무와 가장 짧은 시간이 걸리는 업무를 쌍으로 묶으면 최소한 더 좋은 결과를 얻을 수 있다.

물론 가장 오래 걸리는 업무와 가장 짧게 걸리는 업무의 합이 늘 최적이 되는 건 아니다. 가장 긴 업무 두 개는 걸리는 시간이 비슷하지만, 가장 짧은 업무 두 개는 걸리는 시간이 많이 차이 나는 경우를 생각해 보면 쉽다. 예를 들어 업무에 걸리는 시간이 각각 1,8,9,10인 경우 모든 업무를 마치는 데 걸리는 시간은 1+10이 아니고 8+9=17이다.

결론적으로 업무에 걸리는 시간순으로 정렬한 뒤, 가장 짧게 걸리는 업무와 가장 오래 걸리는 업무끼리 차례대로 쌍으로 묶어 주면 된다. 예를 들어 업무에 걸리는 시간이 각각 5,2,1,6,4,4라고 하자. 이를 정렬하면 1,2,4,4,5,6이 되고, 따라서 (1,6),(2,5),(4,4)를 쌍으로 묶어주면 된다.

```java
private static class PairedTasks {
    public Integer task1;
    public Integer task2;

    public PairedTasks(Integer task1, Integer task2) {
        this.task1 = task1;
        this.task2 = task2;
    }
}

public static List<PairedTasks> optimumTaskAssignment(List<Integer> taskDurations) {
    Collections.sort(taskDurations);
    List<PairedTasks> optimumAssignments = new ArrayList<>();
    for (int i = 0, j = taskDurations.size() - 1; i < j; i++,j--) {
        optimumAssignments.add(
            new PairedTasks(taskDurations.get(i), taskDurations(j))
        );
    }
    return optimumAssignments;
}
```

시간 복잡도는 정렬하는 데 걸리는 시간인 $O(n \log n)$과 같다.

## 문제 17.2 기다리는 시간을 최소화하기

데이터베이스는 SQL 쿼리에 대한 응답을 반환해야 한다. 각 쿼리를 처리하는 데 걸리는 시간은 이미 알고 있다. 이 애플리케이션에서 데이터베이스는 임의의 순서대로 한번에 하나의 쿼리만 처리해야 한다. 따라서 각 쿼리를 처리하기 전에 기다리는 시간이 존재한다.

각 쿼리를 처리하는 데 걸리는 시간이 주어졌을 때, 총 대기 시간이 최소화되려면 어떤 순서로 쿼리를 실행해야 하는지 알아보자. 예를 들어 각 쿼리를 처리하는 데 걸리는 시간이 <2,5,1,3>일 때, 이대로 쿼리를 처리하면 전체 기다리는 시간은 0 + (2) + (2 + 5) + (2 + 5 + 1) = 17이다. 하지만 가장 오래 걸리는 쿼리부터 시간이 감소하는 순서대로 처리한다면 기다리는 시간은 0 + (5) + (5 + 3) + (5 + 3 + 2) = 23이다. 아래에서 보겠지만, 가장 최소로 기다리는 시간의 합은 10이다.

> 힌트: 극단적인 값에 초점을 맞추라.

모든 가능한 스케줄을 나열한 뒤에 가장 적게 기다리는 것을 고르면 된다. 그런데 이 방법의 복잡도는 굉장히 높다. n개의 쿼리가 있을 때, $O(n!)$ 시간이 걸린다.

직관적으로 생각하면 시간이 적게 걸리는 쿼리를 먼저 처리하는 게 나아 보인다. 왜냐하면 각 쿼리를 처리하는 데 걸리는 시간은 남아 있는 모든 쿼리의 기다리는 시간에 추가되기 때문이다. 따라서 시간이 오래 걸리는 쿼리가 시간이 적게 걸리는 쿼리 앞에 있을 때, 이를 맞바꾸면 이 둘 사이에 존재하는 모든 쿼리의 기다리는 시간을 줄일 수 있고, 다른 쿼리의 기다리는 시간에 영향을 미치지도 않는다. 물론 시간이 오래 걸리는 쿼리 자체의 기다리는 시간은 증가하지만, 그만큼 시간이 적게 걸리는 쿼리의 기다리는 시간이 줄어들어서 상쇄된다. 따라서 처리 시간이 증가하는 순서대로 쿼리를 정렬한 뒤 차례대로 실행하면 된다.

주어진 예제에서 최적의 스케줄은 처리 시간이 증가하는 순서대로 쿼리를 배치했을 때이다. 따라서 전체 기다리는 시간은 0 + (1) + (1 + 2) + (1 + 2 + 3) = 10이 된다. 가장 오래 걸리는 쿼리부터 시간이 감소하는 순서대로 스케줄링한 결과는 최악의 방법이었다.

```java
public static int minimumTotalWaitingTime(List<Integer> serviceTimes) {
    // serviceTimes을 증가하는 순서대로 정렬한다.
    Collections.sort(serviceTimes);

    int totalWaitingTime = 0;
    for (int i = 0; i < serviceTimes.size(); i++) {
        int numRemainingQueries = serviceTimes.size() - (i + 1);
        totalWaitingTime += serviceTimes.get(i) * numRemainingQueries;
    }
    return totalWaitingTime;
}
```

시간 복잡도는 정렬하는 데 걸리는 시간과 같은 $O(n \log n)$이다.

## 문제 17.3 모든 구간을 커버하기

공장에서 몇 가지 업무를 책임져야 하는 현장감독을 생각해 보자. 각 업무는 정해진 시간에 시작해서 정해진 시간에 끝난다. 현장감독은 공장에 직접 방문해서 업무가 잘 돌아가는지 확인하고 싶어 한다. 여러분이 해야 할 일은 현장감독이 공장을 방문하는 횟수를 최소화하는 것이다. 현장감독은 매번 방문할 때마다, 현재 진행 중인 모든 업무를 확인한다. 현장감독은 특정 시간에 현장을 방문하고, 정확히 그 시간에 수행되는 업무만을 확인할 수 있다. 예를 들어 [0,3], [2,6], [3,4], [6,9]의 시간에 수행되는 업무 4개가 있을 때, 현장감독이 0,2,3,6시간에 방문하면 모든 업무를 확인할 수 있다. 하지만 3,6시간에만 방문해도 모든 업무를 확인할 수 있다. 이 문제를 추상화하면 다음과 같다.

닫힌 구간의 집합이 주어졌을 때, 가장 적은 숫자로 모든 구간을 커버할 수 있는 알고리즘을 설계하라.

> 힌트: 극단적인 입력값을 생각해 보라.

각 구간의 끝에 있는 숫자만 고려해도 이 문제를 풀 수 있다는 사실을 기억하길 바란다. 무식한 방법은 모든 가능한 끝부분의 숫자의 부분 집합을 나열한 뒤, 해당 부분 집합이 모든 구간을 커버하는지 확인하는 것이다. 만약 모든 구간을 커버하고 현재의 부분 집합의 크기가 이전보다 작다면 그 결과를 갱신한다. 모든 부분 집합의 개수는 $2^k$이므로, 이 방법의 시간 복잡도는 굉장히 높다.

간단하게 모든 구간의 왼쪽 끝지점을 반환해도 된다. 이렇게 하면 굉장히 빠르게 부분 집합을 구할 수 있지만 앞에서도 살펴봤듯이 그 결과가 항상 최소의 개수는 아니다. 이와 비슷하게, 가장 많은 구간을 지나치는 지점을 그리디하게 선택하더라도 그 결과가 부분최적이 될 가능성이 있다. 예를 들어 [1,2], [2,3], [3,4], [2,3], [3,4], [4,5]의 경우를 생각해 보자. 3은 여섯 개의 구간 중, 네 개의 구간에서 등장한다. 하지만 3을 선택한다면 [1,2]와 [4,5]를 커버하지 못하므로 추가로 두 개의 지점을 더 선택해야 한다. 그런데 2와 4 지점을 선택한다면, 각각 3개의 구간을 커버해서 단 두개의 지점으로 모든 구간을 커버할 수 있다.

극단적인 경우에 초점을 두는 것이 좋다. 특히 첫 번째로 끝나는 지점, 즉 구간의 오른쪽 끝점의 위치가 가장 작은 것에 집중해 보자. 이 지점을 커버하기 위해서는 해당 구간을 지나는 부분을 선택해야 한다. 그중에서도 반드시 오른쪽 끝 지점을 선택해야 한다. 왜냐하면 그 앞의 어떤 지점을 선택하든지 끝 지점을 선택하는 것보다 더 나은 선택이 아니기 때문이다. (이게 참이 아니라면, 우리가 선택한 그 구간의 끝지점이 첫 번째로 끝나는 지점이 아니라는 뜻이 된다.) 끝 지점을 선택한 뒤에, 커버되는 모든 구간을 삭제한 뒤 남아 있는 구간들로 앞의 과정을 반복한다.

앞의 과정을 다음 알고리즘으로 나타낼 수 있다. 모든 구간을 오른쪽 끝 지점을 기준으로 정렬한다. 첫 번째 구간의 오른쪽 끝 지점을 선택한다. 커버되지 않는 첫 번째 구간이 나올 때까지 정렬된 구간을 차례대로 순회한다. 커버되지 않는 구간을 발견하는 순간 해당 구간의 오른쪽 끝 지점을 선택하고 앞의 과정을 반복한다.

[1,2],[2,3],[3,4],[2,3],[3,4],[4,5]의 예제가 있을 때, 이를 오른쪽 끝점을 기준으로 정렬하면 [1,2],[2,3],[2,3],[3,4],[3,4],[4,5]가 된다. 첫 번째 구간의 오른쪽 끝 지점은 2이고, 이 지점은 처음 세 개의 구간을 커버한다. 다음에 [3,4]를 만나게 되면 이 구간의 오른쪽 끝 지점인 4를 선택해서 [3,4],[3,4],[4,5]를 커버한다.  남아 있는 구간이 더 이상 없으므로 {2,4}가 모든 구간을 커버하는 가장 적은 숫자의 집합이 된다.

```java
public static class Interval {
    public int left, right;

    public Interval(int l, int r) {
        this.left = l;
        this.right = r;
    }
}

public static Integer findMinimumVisits(List<Interval> intervals) {
    // 오른쪽 끝점을 기준으로 구간을 정렬한다.
    Collections.sort(intervals, new Comparator<Interval>(){
        @Override
        public int compare(Interval i1, Interval i2) {
            return Integer.compare(i1.right, i2.right);
        }
    });
    List<Integer> visits = new ArrayList<>();
    Integer lastVisitTime = Integer.MIN_VALUE;
    Integer numVisits = 0;
    for (Interval interval : intervals) {
        if (interval.left > lastVisitTime) {
            // 현재의 오른쪽 끝점인 lastVisitTime은 더 이상 커버하는 구간이 없다.
            lastVisitTime = interval.right;
            ++numVisits;
        }
    }
    return numVisits;
}
```

각 인덱스에서 걸린 시간은 $O(1)$이므로 정렬을 한 이후에 걸린 시간은 총 $O(n)$이다. 여기서 n의 구간은 개수이다. 하지만 그전에 정렬을 해야 하므로 이 알고리즘의 전체 시간 복잡도는 정렬을 하는 데 필요한 $O(n \log n)$과 같다.

## 불변식

> 효과적인 알고리즘을 설계하는 일반적인 방법은 불변식(invariants)을 사용하는 것이다. 불변식은 간단히 말하면, 프로그램이 실행되는 동안 참인 조건을 뜻한다. 이 조건은 프로그램의 변수 값이나 제어 논리에 있을 수 있다.

불변식을 잘 선택하면 차선책이나 다른 방법에 의존하는 해법들을 배제하여 좀 더 최적의 해결책을 찾을 수 있다.

예를 들어 이진탐색은 알고리즘이 실행되는 동안 모든 가능한 후보자를 고려한다는 불변식을 유지한다.

정렬 알고리즘은 불변식을 사용한 알고리즘 설계를 잘 보여준다. 선택 정렬을 예로 들어 보자. 선택 정렬은 가장 작은 원소를 차례대로 찾은 뒤 그들을 올바른 위치로 옮기는 과정을 반복한다. 0번 인덱스에서 시작하는 부분배열의 크기를 점차 키워가면서 해당 부분배열이 언제나 정렬되어 있다는 불변식을 유지하고 있는 셈이다. 따라서 불변식을 만족하는 부분배열의 원소는 나머지 원소보다 작거나 같고, 전체 배열은 기존 배열을 재배열한 결과와 같다.

더 복잡한 예제를 다뤘던 문제 14.7의 해법을 생각해 보자. 이 방법은 $a + b\sqrt{2}$꼴을 만족하는 첫 k개의 숫자를 $O(k)$ 시간에 찾는다. 이 해법의 핵심은 이러한 숫자를 정렬된 순서대로 처리한다는 점이다. 코드에 나와 있는 큐는 여러 가지 불변식을 만족하는데, 예를 들어 큐 안의 원소들은 정렬되어 있고 중복된 원소가 있어선 안 되며, 원소 사이의 분리는 제한적이라는 것이다.

### 불변식 부트 캠프

정렬된 배열과 숫자 하나가 주어졌을 때 배열 안의 숫자 두 개를 더해서 주어진 숫자를 만들 수 있는지 확인하는 프로그램을 작성한다고 해 보자. 예를 들어 <-2,1,2,4,7,11>이 주어졌을 때, 해당 배열의 숫자 두 개를 더해서 6,0,13은 만들 수 있지만 10은 만들 수 없다.

이 문제를 푸는 방법은 여러 가지다. 그중 하나는 모든 쌍을 순회하거나 주어진 숫자에서 해당 항목을 뺀 값이 배열의 원소에 존재하는지 찾는 것이다. 가장 효율적인 방법은 불변식을 사용하는 것이다. 해법이 존재한다면, 해법이 항상 존재하는 부분배열을 찾는다. 부분배열은 처음에 전체배열로 초기화되고, 한쪽 또는 다른 쪽부터 반복해서 줄어든다. 축소는 배열의 정렬을 사용하는데, 가장 왼쪽 값과 가장 오른쪽 값을 더한 값이 대상보다 작다면 가장 왼쪽 값은 배열의 다른 어떤 원소와 더하더라도 대상 값을 만들 수 없다. 오른쪽 끝 원소에 대해서도 비슷한 논리를 적용할 수 있다.

```java
public static boolean hasTwoSum(List<Integer> A, int t) {
    int i = 0, j = A.size() - 1;
    while(i <= j) {
        if (A.get(i) + A.get(j) == t) {
            return true;
        } else if (A.get(i) + A.get(j) < t) {
            ++i;
        } else { // A[i] + A[J] > t
            --j;
        }
    }
    return false;
}
```

배열의 길이가 n일 때 시간 복잡도는 $O(n)$이다. 변수 두 개로 부분배열을 표현할 수 있으므로 공간 복잡도는 $O(1)$이다.

### 불변식 문제를 풀기 전 꼭 알고 있어야 할 내용

- 알고리즘을 설계할 때, 불변식 사용 여부를 결정하는 핵심 전략은 **작은 예제**를 통해 불변식의 가설이 맞는지 확인하는 것이다. [문제 17.4, 문제 17.6]
- 종종 불변식은 가능한 입력 집합의 부분 집합(예를 들어 부분배열)이 된다. [문제 17.4, 문제 17.7]

## 문제 17.4 세 개의 원소를 합해 원하는 숫자를 얻을 수 있는지 확인하기

배열과 숫자 하나가 주어졌을 떄, 배열 안의 원소 세 개를 더해서 주어진 숫자를 만들 수 있는지 확인하는 알고리즘을 설계하라. 배열 안의 원소는 중복이 가능하다. 예를 들어 <11,2,5,7,3>이 있을 때, 3,7,11 혹은 5,5,11을 합하면 21을 만들 수 있다. 21을 만들 때 5를 두 번 사용한 것처럼, 같은 원소를 여러 번 사용해도 된다. 하지만 어떤 세 원소를 더하더라도 22를 만들 수는 없다.

> 힌트: 두 개 이상의 원소를 더해서 주어진 숫자가 되는지 확인하려면 어떻게 해야 할까?

무식한 방법은 삼중 루프를 사용해서 모든 가능한 경우를 살펴보는 것이다. 배열의 길이가 n일 때 이 방법의 시간 복잡도는 $O(n^3)$이고 공간 복잡도는 $O(1)$이다.

입력 배열을 A, 주어진 숫자를 t라고 하자. 배열의 원소를 해시테이블에 저장하면 알고리즘의 시간 복잡도를 $O(n^2)$까지 개선할 수 있다. 그다음 원소쌍을 순회하면서 $A[i] + A[j]$에 대해 $t - (A[i] + A[j])$가 해시테이블에 있는지 확인하면 된다. 공간 복잡도는 $O(n)$이 필요하다.

입력 배열을 정렬하면 추가 공간 복잡도를 사용하지 않을 수 있다. A를 정렬한 뒤 A[i]에 대해서 $A[j] + A[k] = t - A[i]$를 만족하는 j와 k를 찾으면 된다. A[j]를 순회하는 동시에 이진 탐색을 사용해서 A[k]를 찾으면 $O(n \log n)$에 j와 k를 찾을 수 있다.

A[0] + A[n - 1]에서 시작하면 시간 복잡도를 $O(n)$으로 개선할 수 있다. 만약 이 값이 t - A[i]와 같다면 여기서 바로 끝낸다. 만약 A[0] + A[n-1] < t - A[i]라면 A[1] + A[n-1]로 옮겨 간다. 왜냐하면 A[n-1]이 배열 A에서 가장 큰 값이므로 A[0]과 쌍을 이루어서 t-A[i]를 만족할 수 없기 때문이다. 비슷하게 A[0] + A[n-1] > t - A[i]라면, A[0] + A[n-2]로 넘어간다. 이 방법은 반복적으로 원소를 하나씩 제거해 나간다. 매번 $O(1)$ 시간을 사용하므로 A[j] + A[k] = t - A[i]를 만족하는 A[j]와 A[k]를 찾는 데 $O(n)$ 시간이 걸린다. 여기서 원하는 값을 원소 두 개의 합으로 만들 수 있으려면, 현재의 부분배열 안에 반드시 그 두 개의 원소가 존재해야 한다.

앞의 예제에서 배열을 정렬하면 <2,3,5,7,11>이 된다. A[0] = 2에 대해 A[0] + A[j] + A[k] = 21이 되는 A[j]와 A[k]를 찾으려면 두 원소의 합이 21-2=19가 되는 j와 k를 찾으면 된다.

다음은 이를 구현한 코드이다.

```java
public static boolean hasThreeSum(List<Integer> A, int t) {
    Collections.sort(A);
    for (Integer a : A) {
        // 두 원소의 합이 t - a가 되는 원소가 A에 있는지 확인한다.
        if (TwoSum.hasTwoSum(A, t - a)) {
            return true;
        }
    }
    return false;
}
```

추가 공간 복잡도는 $O(1)$이다. 전체 시간 복잡도는 우선 정렬에 $O(n \log n)$ 시간이 소요된다. 그다음 정렬된 배열에서 두 원소의 합이 특정값이 되는지 확인하는 $O(n)$을 n번 수행하므로 $O(n^2)$이 된다.

## 문제 17.5 다수 원소 찾기

어떤 애플리케이션에서는 주어진 수열에서 일정 비율보다 많이 등장하는 원소를 찾아야 하는 경우가 발생한다. 예를 들어 네트워크 대역폭을 과도하게 사용하거나 HTTP 요청을 가장 많이 한 사용자를 찾아내고 싶을 수 있다. 이를 간단하게 표현한 다음 문제를 생각해 보자.

어떤 문자열을 읽고 있다고 가정하자. 특정 문자가 문자열의 절반 이상에서 등장한다. 이 문자를 '다수(majority) 원소'라고 부르자. '다수 원소'가 있다는 건 알지만, 문자열 내의 위치까지는 알지 못한다. 문자열이 스트리밍 형태로 입력된다고 했을 때, 한 번만 읽어서 어떤 원소가 '다수 원소'인지 확인하는 프로그램을 작성하라. 예를 들어 입력이 <b,a,c,a,a,b,a,a,c,a>라면 a가 '다수 원소'가 된다(10번 중 6번 등장했으므로).

> 힌트: 입력에 '다수 원소'가 있다는 사실을 미리 알고 있으므로 이를 바탕으로 다수가 아닌 원소를 제거해 나가보자.

무식한 방법은 해시 테이블에 해당 원소가 몇 번이나 반복됐는지 기록하는 것이다. 이 방법은 원소의 개수가 n개일 때 시간 복잡도가 $O(n)$이고 공간 복잡도 또한 $O(n)$이다.

무작위 샘플링 방법은 적은 공간으로 다수 원소를 찾는 데 종종 쓰인다. 정확도가 높은 편이지만 완벽하진 않다.

더 나은 알고리즘에 대한 생각은 다음과 같다. 원소들을, 다수 원소로 구성된 그룹과 그렇지 않은 그룹으로 나눈다. 다수 원소로 구성된 그룹이 두 번째 그룹의 크기보다 크고 다수 원소는 단 하나뿐이므로, 서로 다른 원소 두 개를 임의로 선택했을 떄 최대 하나의 원소가 다수 원소가 될 수 있다. 두 원소를 모두 제거하더라도 첫 번째 그룹과 두 번째 그룹의 크기 차이는 동일하게 유지되므로 다수 원소는 남아 있는 항목들에서 변하지 않고 그대로 유지된다.

이 알고리즘은 다음과 같이 진행된다. 엔트리를 순회하면서 다수 원소 후보자와 그 후보자가 몇 번 등장했는지 개수를 센다. 다수 원소 후보자는 첫 번째 엔트리로 초기화한다. 남아 있는 엔트리를 순회하면서 현재 후보자와 같은 엔트리를 발견하면 그 개수를 증가시킨다. 만약 후보자와 다른 엔트리를 만나면 개수를 감소시킨다. 카운트된 개수가 0이 되면 후보자를 그 다음 엔트리로 바꾼다.

이를 수학적으로 증명해 보자. n개의 엔트리에서 다수 원소가 m번 등장했다고 하자. 다수 원소의 정의대로 $\frac{m}{n} > \frac{1}{2}$가 된다. 서로 다른 두 개의 원소를 선택했을 때 둘 다 다수 원소가 될 수는 없다. 둘 중 하나가 다수 원소인 경우에 이 둘을 삭제했을 때 전체 원소에 대한 다수 원소의 비율은 $\frac{(m-1)}{(n-2)}$이 되고, 둘 다 다수 원소가 아니라면 그 비율이 $\frac{m}{n-2}$이 된다. $\frac{m}{n} > \frac{1}{2}$일 때 $\frac{m}{(n-2)} > \frac{1}{2}$이고 $\frac{(m-1)}{(n-2)} > \frac{1}{2}$을 증명하는 건 간단하다.

앞에서 나온 예제인 <b,a,c,a,a,b,a,a,c,a>를 살펴보자. 먼저 다수 원소를 b로 초기화한다. 그 다음 원소인 a와 b가 다르므로 다수 원소의 개수는 0이 된다. 따라서 그 다음 원소인 c를 다수 원소 후보자로 선택하고 그 개수를 1로 설정한다. 그 다음 원소가 a이므로 다수 원소의 개수를 0으로 감소한다. 이제 a가 새로운 후보자가 되었다. 하지만 그 다음 원소인 a를 다시 새로운 후보자로 설정한다. 이 후보자의 개수는 마지막까지 0보다 크기 때문에 a가 최종 다수 원소가 된다.

```java
public static String majoritySearch(Iterator<String> inputStream) {
    String candidate = "";
    int candidateCount = 0;
    while (inputStream.hasNext()) {
        String it = inputStream.next();
        if (candidateCount == 0) {
            candidate = it;
            candidateCount = 1;
        } else if (candidate.equals(it)) {
            ++candidateCount;
        } else {
            --candidateCount;
        }
    }
    return candidate;
}
```

각 엔트리를 처리하는 데 $O(1)$의 시간을 사용하므로 전체 시간 복잡도는 $O(n)$이다. 추가 공간 복잡도는 $O(1)$이다.

앞의 코드는 다수 원소가 언제나 존재한다는 가정하에 동작한다. 만약 다수 원소가 존재하지 않는다면, 앞에서 반환하는 결과는 아무 의미 없는 결과일 것이다. 마지막에 한 번 더 입력을 읽으면서 해당 단어가 다수 원소인지 확인하는 과정을 넣을 수도 있다. 문제 24.33에서도 이야기했듯이, 입력에서 n/k번보다 많이 등장하는 원소를 찾을 때도 비슷한 방법을 사용하면 된다.

## 문제 17.6 주유소 문제

모든 도시를 방문한 뒤 시작 도시로 되돌아오려 한다. 도시는 환형으로 연결되어 있고, 각 도시에서는 특정 양의 가스를 구할 수 있다. 모든 도시에서 얻을 수 있는 가스의 총 양은 환형 도로를 한 번 순회하는 데 필요한 가스의 양과 같다. 가스 탱크는 무제한이라고 가정한다. 어떤 도시에서 가스 탱크가 비어 있는 상태로 시작해 환형 도로를 한 번 순회한 다음, 다시 해당 도시로 돌아올 수 있으면 그 도시를 '풍부한(ample) 도시'라고 하자. 그림 17.2에 예제가 표시되어 있다.

주유소 문제에서 어떻게 하면 풍부한 도시를 효율적으로 찾을 수 있을까? 풍부한 도시는 반드시 존재한다고 가정해도 좋다.

> 힌트: 가스를 충분히 채운 상태에서 한 바퀴 순회한다고 생각해 보라. 그리고 도로를 순회하면서 사용한 가스의 양과 각 도시에서 채울 수 있는 가스의 양을 추적해 보라.

무식한 방법은 각 도시에서 시작해서 도로를 순회해 보는 것이다. 도시가 n개일 때 이 방법의 시간 복잡도는 $O(n^2)$이다.

다음과 같은 그리디 알고리즘을 생각해 볼 수도 있다. 예를 들어 가스를 가장 많이 얻을 수 있는 도시에서 시작하거나, 그 다음 도시와 가장 가까운 도시에서 시작해 보는 것이다. 하지만 전부 올바른 방법이 아니다. 앞의 예제를 살펴보자. A 도시에서 가스를 가장 많이 구할 수 있지만 C 도시에 도달할 수 없다. G 도시에서 그 다음인 A 도시까지 가장 가깝고, 거리-가스 비율(100/10)이 가장 좋지만 D 도시에 도달할 수 없다.

도시 간 도로를 순회하면서 사용한 가스의 양을 그래프로 그려 보면 어떤 통찰을 얻을 수 있을 것이다. 앞의 예제를 그래프로 표현한 그림 17.3을 살펴보자. 가스 탱크에 들어 있는 가스의 양은 음수가 될 수 있지만 물리적으로 불가능한 것은 무시하기로 한다. 이 그래프는 X축을 기준으로 환형 시프트를 하거나 Y축을 기준으로 위아래로 위아래로 옮겨도 동일한 그래프가 된다.

진입 당시의 가스 양이 최소가 되는 도시를 살펴보자. 어느 도시에서 출발했는지와 상관없이 가스 양이 최소가 되는 도시는 항상 동일하다. 왜냐하면 이 그래프는 양옆으로 환형 시프트를 하거나 위아래로 옮겨도 동일하기 때문이다. 진입 당시의 가스 양이 최소가 되는 도시를 z라 하자. 여기서 진입 당시의 가스 양이란, 도시에 도착해서 주유를 하기 전의 가스 양을 뜻한다. z에서 시작한 것보다 가스의 양이 더 적은 적이 없었고 z로 돌아갔을 때 가스의 양이 0이 되므로(즉, 도로를 순환하는 데 필요한 전체 가스의 양이 충분하므로) 가스가 바닥나기 전에 도로를 순환할 수 있다. 단, 풍부한 도시가 항상 존재한다는 가정이 있을 때에만 이 논리가 가능하다.

모든 도시를 통과하면서 가스 양의 변화를 시뮬레이션하면 진입 당시 가스 양이 최소가 되는 도시 z를 쉽게 구할 수 있다.

```java
private static class CityAndRemainingGas {
    public Integer city;
    public Integer remainingGallons;

    public CityAndRemainingGas(Integer city, Integer remainingGallons) {
        this.city = city;
        this.remainingGallons = remainingGallons;
    }
}

private static final int MPG = 20;
```

시간 복잡도는 $O(n)$이고 공간 복잡도는 $O(1)$이다.

## 문제 17.7 수직선 쌍에 담을 수 있는 물의 최대 양 구하기

x=0에서 시작하는 Y축에 평행한 수직선의 집합을 표현한 정수 배열이 있다. 그림 17.4(a)를 살펴보자. 이 문제의 목적은 X축에 위치한 가장 많은 물을 담을 수 있는 수직선의 쌍을 구하는 것이다. 그림 17.4(b)에 그 예제가 나와 있다.

정수 배열이 주어졌을 때 물을 최대로 담을 수 있는 수직선 쌍을 반환하는 프로그램을 작성하라.

> 힌트: 0과 n-1을 시작점으로 해서 이동하라.

A를 배열이라고 하고 그 길이를 n이라 하자. 간단하게 생각할 수 있는 무식한 방법으로는 $O(n^2)$ 해법이 있다. i < j의 쌍 (i,j)에 대해 $(j-i) \times \min{A[i], A[j]}$ 사이에 물을 담을 수 있는지 확인한다. 물을 담을 수 있는지 확인하는 과정은 $O(1)$ 시간에 해결할 수 있다. 물을 담을 수 있는 $(i,j)$ 쌍 중에 최댓값이 최종 해법이 된다.

시간 복잡도를 개선하기 위해 분할 정복법을 생각해 볼 수 있다. A의 왼쪽 절반, A의 오른쪽 절반, 그리고 A의 중간 지점에 걸쳐서 담을 수 있는 물의 최대양을 구할 수 있다. 중간 지점에 걸쳐서 담을 수 있는 최대양을 구할 때는 왼족 절반의 n/2개와 오른쪽 절반의 n/2개의 조합을 통해 구할 수 있다. 따라서 이 분할 정복법의 시간 복잡도 $T(n) = 2T(n/2) + O(n^2/4)$가 되고, 따라서 $T(n) = O(n^2)$이다. 이 방법은 무식한 방법보다 나은 점이 없고 코딩하기도 까다롭다.

좋은 시작점은 가장 넓은 폭인 0과 n-1을 고려하는 것이다. 여기에 담을 수 있는 최대 양, 즉 $((n-1)-0) \times \min{(A[0], A[n-1])}$을 기록한다. $A[0] > A[n-1]$이라면, k > 0인 경우 k와 n-1 사이에 담은 물은 0과 n-1 사이에 담은 물보다 적다. 따라서 앞으로는 0과 n-2 사이에 담을 수 있는 물의 양에 집중하면 된다. $A[0] \le A[n-1]$인 경우에는 반대다. 이때는 0을 다시 고려할 필요가 없다.

이를 반복적으로 적용하면서 최대로 담을 수 있는 물의 양을 기록하고, 반드시 고려해야 할 부분배열의 범위를 좁혀나간다. 본질적으로 너비와 높이를 절충할 수 있는 가장 좋은 방법을 찾는 것이다.

```java
public static int getMaxTrappedWater(List<Integer> heights) {
    int i = 0, j = heights.size() - 1, maxWater = 0;
    while (i < j) {
        int width = j - i;
        maxWater = Math.max(maxWater, width * Math.min(heights.get(i), heights.get(j)));
        if (heights.get(i) > heights.get(j)) {
            --j;
        } else {
            ++i;
        }
    }
    return maxWater;
}
```

반복적으로 수직선을 하나 혹은 두 개씩 제거해 나가고, 매번 $O(1)$의 시간을 사용하므로 전체 시간 복잡도는 $O(n)$이 된다.

## 문제 17.8 스카이라인에서 가장 큰 직사각형 구하기

인접하게 배열된 건물의 리스트가 주어져 있다. 각 건물은 일정한 단위 폭과 높이를 가지고 있다. 이 건물들이 도시의 스카이라인을 표현한다고 했을 때, 어떤 건축사가 이 스카이라인에 포함되는 가장 큰 직사각형의 면적을 알고싶어 한다. 그림 17.5에 예제가 표현되어 있다.

일정한 폭을 가지는 인접한 건물들의 높이를 나타내는 배열 A가 있다고 하자. 스카이라인 안에서 면적이 가장 넓은 직사각형을 구하는 알고리즘을 설계하라.

> 힌트: i번째 건물의 높이가 A[i]일 때, 이 건물을 포함하면서 넓이가 가장 넓은 직사각형을 어떻게 효율적으로 찾을 수 있을까?

무식한 방법은 모든 (i,j) 쌍에 대해 A[i,j]의 부분배열에서 높이가 가장 작은 건물을 구한 뒤 이 높이에 j-1+1을 곱하는 것이다. A의 길이가 n일 때 이 방법의 시간 복잡도는 $O(n^3)$이 된다. 이 방법은 $j > i$인 j를 순회할 때 현재까지의 가장 낮은 높이를 저장해 나간다면 $O(n^2)$으로 손쉽게 개선할 수 있다. 하지만 이 방법으로는 $O(n^2)$보다 더 개선할 만한 여지가 보이지 않는다.

또 다른 무식한 방법은 모든 i에 대해 A[i]의 높이보다 낮은 건물이 나올 때까지 왼쪽과 오른쪽을 확장해 나가는 것이다. 본질적으로 가장 큰 직사각형의 기둥 역할을 하는 어떤 건물 i를 찾는 과정이다. 앞의 예제에서 G를 기둥으로 하는 가장 큰 직사각형은 1과 11사이의 직사각형이고, F를 기둥으로 하는 가장 큰 직사각형은 3과 6 사이의 직사각형이다.

i번째 건물을 포함하는 가장 큰 직사각형은 i를 기준으로 왼쪽 오른쪽으로 한 번씩 순회하면서 손쉽게 찾을 수 있다. 0과 n-1 사이의 모든 i에 대해 앞의 과정을 수행해야 하므로 이 방법의 시간 복잡도는 $O(n^2)$이다.

이 방법은 시간 복잡도를 개선할 여지가 보인다. 즉, 어떤 건물을 기준으로 왼쪽과 오른쪽으로 순회하는 경우를 생각해 보자. i번째 건물을 처리한다고 했을 때, 오른쪽으로 얼마나 순회해야 하는지 알지 못한다. 하지만 왼쪽에 있는 건물들 중 A[i]보다 높이가 높았기 때문에 i를 넘어서 더 이상 확장을 하지 못했던 건물들은 알 수 있다. 예를 들어 그림 17.5에서 B,D,E(F보다 건물의 높이가 높은 건물들)는 F를 넘어서 확장하지 못했던 건물들이다.

예제를 좀 더 자세히 살펴보면, F가 기준일 때 B는 더 이상 고려할 필요가 없다는 것을 알 수 있다. 왜냐하면 그 사이에 위치한 C가 이미 건물 B의 확장을 방해했기 때문이다. C 또한 고려할 필요가 없다. 왜냐하면 G의 높이가 C의 높이와 같고 G가 C의 확장을 방해하지 않았으므로 G와 C를 포함한 가장 큰 직사각형은 같을 것이기 때문이다. 이를 일반화하면, 건물을 하나씩 살펴보면서 아직 확장을 방해받지 않은 건물들을 추적하는 작업이 필요하다. 또한, 현재 건물과 높이가 같은 이전의 건물들을 추적하는 작업이 필요하다. 또한, 현재 건물과 높이가 같은 이전의 건물을 현재 건물로 교체할 수 있다. 이러한 건물들을 유효한 건물 기둥 집합이라고 하자.

초기에 유효한 건물 기둥 집합은 존재하지 않는다. 0에서 12까지 순회하면서 유효한 건물 기둥 집합은 다음과 같이 변한다.
{A},
{A,B},
{A,C},
{A,C,D},
{A,C,D,E},
{A,C,F},
{A,G},
{A,G,H},
{A,G,I},
{A,G,J},
{A,K},
{L},
{L,M}

건물이 유효한 건물 기둥 집합에서 제거될 때마다 해당 건물이 오른쪽으로 얼마 만큼 확장되었는지 알 수 있다. 예를 들어 C에 도달했을 때 B를 기둥으로 하는 직사각형은 2에서 끝났고, F에 도달했을 떄 D와 E를 기둥으로 하는 직사각형은 5에서 끝났다.

유효한 건물 기둥 집합에서 건물을 제거했을 때, 해당 건물을 기준으로 왼쪽으로 얼마만큼 확장했는지 어떻게 찾을 수 있을까? 단순하게 건물 기둥 집합에서 해당 건물보다 낮은 건물 중에 가장 가까운 건물이 무엇인지 찾아보면 된다. 예를 들어 우리가 F에 도달했을 때 유효한 건물 기둥 집합은 {A,C,D,E}가 된다. E와 D가 F보다 높이가 높으므로 집합에서 삭제한다. E가 기둥이 되는 가장 큰 직사각형의 높이는 6이고 D 이후, 즉 4 위치에서 시작하므로 그 넓이는 $6 \times (5-4)=6$이 된다. D가 기둥이 되는 가장 큰 직사각형의 높이는 5이고 C 이후, 즉 3 위치에서 시작하므로 그 넓이는 $5 \times (5-3)=10$이 된다.

유효한 건물 기둥 집합을 저장하는 여러 가지 자료구조가 존재한다. 그중에서 기 알고리즘을 효율적으로 구현할 수 있는 자료구조를 사용해야 한다. 새로운 건물을 처리할 때, 확장이 불가능한 건물을 유효한 건물 기둥 집합에서 찾아야 한다. 유효한 건물 기둥 집합에 건물을 삽입하거나 집합에서 건물을 삭제할 때 후입선출법을 사용하므로, 이 집합을 유지하는 데는 스택 자료구조를 선택하는 게 합리적이다. 유효한 건물 기둥 집합에서 가장 오른쪽에 있는 건물이 스택의 가장 위에 있다. 스택을 사용하면 왼쪽으로 얼마나 확장 가능하지를 확인할 떄도 유용하다. 스택에 들어 있는 건물을 차례대로 살펴보면 된다. 예를 들어 F를 처리한다고 했을 때 스택에는 A,C,D,E가 차례로 들어 있다. F와 E의 높이를 비교하면 E가 F에 의해 확장을 방해받으므로(즉, E의 높이가 F의 높이보다 높으므로) E를 기둥으로 하는 직사각형은 5까지 확장할 수 있다. 그 다음 건물은 D가 된다. D의 높이는 E의 높이보다 낮으므로 E를 기둥으로 하는 건물은 D의 끝점인 4에서 시작한다는 사실을 알 수 있다.

알고리즘이 거의 완성되었다. 남은 건 순회가 끝나는 시점에서 어떻게 해야 할지에 대한 부분이다. 순회가 끝났을 때, 스택에 최소한 마지막 건물이 들어 있을 것이므로 스택은 비어 있지 않은 상태다. 앞에서 설명한대로 이 건물을 처리하면 된다. 다만 마지막까지 남아 있는 건물을 기둥으로 하는 직사각형의 오른쪽 끝은 항상 n이다. 여기서 n은 배열의 건물 개수를 말한다. 앞의 예제에서 L과 M은 마지막까지 스택에 남아 있는 건물이고, 이들을 기둥으로 하는 직사각형의 오른쪽 끝점은 13이다.

```java
public static int calculateLargestRectangle(List<Integer> heights) {
    Deque<Integer> pillarIndices = new ArrayDeque<>();
    int maxRectangleArea = 0;
    // heights.size() - 1이 아닌 heights.size()만큼 순회를 한다.
    // 그렇게 해야 직사각형의 넓이를 균일하게 처리할 수 있다.
    for (int i = 0; i <= heights.size(); i++) {
        while (!pillarIndices.isEmpty() && isNewPillarOrReachEnd(heights, i, pillarIndices.peekFirst())) {
            int height = heights.get(pillarIndices.removeFirst());
            int width = pillarIndices.isEmpty() ? i : i - pillarIndices.peekFirst() - 1;
            maxRectangleArea = Math.max(maxRectangleArea, height * width);
        }
        pillarIndices.addFirst(i);
    }
    return maxRectangleArea;
}

private static boolean isNewPillarOrReachEnd(List<Integer> heights, int currIdx, int lastPillarIdx) {
    return currIdx < heights.size()
        ? heights.get(currIdx) < heights.get(lastPillarIdx)
        : true;
}
```

시간 복잡도는 $O(n)$이다. 건물을 처리할 때 각 건물에서 사용한 시간은 스택에 삽입한 건물과 스택에서 제거한 건물의 개수에 비례한다. 어떤 건물에서는 여러 번의 삭제를 수행하지만, 전체 수행한 삽입과 삭제의 횟수는 각각 n이다. 왜냐하면 각 건물 i는 최대 한 번 스택에 삽입될 것이고, 스택에서 삭제되는 횟수가 하나 이상이 될 수 없기 때문이다. 스택에 남아 있는 원소를 처리하는 데 필요한 시간 복잡도 또한 $O(n)$이 된다. 왜냐하면 결국 스택에 남게 될 원소의 개수는 $O(n)$이고 각 원소를 처리하는 데 $O(1)$ 시간이 걸리기 때문이다. 따라서 전체 시간 복잡도는 $O(n)$이 된다. 스택에 최대로 들어갈 원소의 개수는 n개이므로 전체 공간 복잡도는 $O(n)$이 된다. 스택에 n개의 원소가 들어갈 경우는 건물의 높이가 증가하는 순서대로 입력될 때이다.
