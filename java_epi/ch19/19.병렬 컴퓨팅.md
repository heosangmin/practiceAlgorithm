# 19장 병렬 컴퓨팅

```text
컴퓨터는 예측하지 못한 순간에 쏟아지는 다양한 메시지에 적절하게 반응해야 한다. 이런 상황은 여러 대의 컴퓨터가 서로 맞물려 있는 모든 정보 시스템에서 발생할 수 있다.
- <Cooperation sequential processes>, 에츠허르 데이크스트라(E. W. Dijkstra), 1965
```

병렬 컴퓨팅은 점차 많이 사용되고 있다. 노트북과 데스크톱에서는 이미 다중 프로세서가 공유 메모리를 통해 통신하고 있으며, 네트워크를 통해 통신하는 여러 컴퓨터의 집합인 클러스터는 복잡한 계산에 이용된다..

병렬화는 다음과 같은 장점이 있다.

- 고성능: 하나의 작업을 수행하는 프로세서가 많을수록 (보통) 작업을 더 빨리 끝낼 수 있다.
- 더 나은 리소스 이용: 프로그램을 수행하는 동안 다른 프로그램은 디스크나 네트워크를 기다릴 수 있다.
- 공정성: 하나의 프로그램만 돌아가는 것이 아니라, 동시간대에 다른 사용자나 프로그램이 하나의 컴퓨터를 공유한다.
- 편리성: 여러 프로그램이 동시에 부분 작업을 수행하는 것이 하나의 프로그램이 모든 부분 작업을 관리하는 것보다 개념적으로 더 간단할 수 있다.
- 실패 허용(fault tolerance): 웹 페이지를 보여 주는 컴퓨터가 어떤 클러스터 내에서 고장났을 때, 다른 컴퓨터가 이를 대신할 수 있다.

병렬 컴퓨팅의 실제 애플리케이션의 예제로는 그래픽 사용자 인터페이스(GUI)가 있다. 그래픽 사용자 인터페이스는 사용자 인터페이스를 담당하는 전담 스레드가 있다. 같은 시간에 다른 스레드는 네트워크 통신을 담당하거나 그 결과를 UI 스레드에 넘겨주는 역할을 한다. 이렇게 하면 반응성을 높일 수 있다. 또한 Java의 가상 머신(하나의 스레드가 사용자의 코드를 수행하는 동안 다른 스레드가 가비지 컬렉션을 수행한다), 웹 서버(하나의 논리적 스레드가 하나의 사용자의 요청을 담당한다), 과학적 수식 계산(커다란 행렬 곱셈은 여러 개의 컴퓨터로 나누어서 계산한다), 웹 검색(여러 컴퓨터가 웹문서를 긁어오고, 인덱스를 만들고, 결과를 사용자에게 반환한다) 등의 예제가 있다.

병렬 컴퓨팅의 두 가지 주요 모델은 프로세서가 같은 메모리 장소를 공유할 수 있는 메모리 공유 모델과 프로세서가 다른 프로세서에게 메시지를 명시적으로 보내야 하는 분산 메모리 모델이다. 메모리 공유 모델은 다중 코어의 경우에 더 적합하고 분산 메모리 모델은 클러스터의 경우에 더 적합하다. 이번 장의 문제는 공유 메모리 모델에 초점을 맞출 것이다.

병렬 프로그램을 올바르게 작성하는 것은 어려운 일이다. 왜냐하면 두 컴포넌트 간의 상호작용을 파악하기가 꽤 어렵기 때문이다. 그중에서도 경쟁(race) 문제가 가장 까다롭다. 경쟁이란 두 개의 명령이 동시에 같은 메모리 주소에 접근하고, 하나의 명령어가 무엇인가를 쓰려고(write) 하는 상황을 말한다. 병렬 프로그램을 올바르게 작성하기 어렵게 하는 요인들은 몇 가지가 더 있다.

- 고갈: 자원이 필요하지만 확보할 수 없을 때(문제 19.6)
- 데드락: A 스레드가 락 L1을 취득하고 B 스레드가 락 L2를 취득한 상태에서 A는 L2를 취득하려 하고, B는 L1을 취득하려 할 때
- 라이브락: 프로세서가 어떤 연산을 반복 실행하지만 계속 실패할 때

이러한 이유로 발생하는 버그는 테스트에서 찾기 어렵다. 또한 이러한 버그는 요청 패턴에 따라 달라질 수 있어서 재현하기 힘들기 때문에 디버깅도 어렵다. 그리고 병렬화에 따른 성능을 인지하기도 어렵다. 프로세서의 개수가 많아도 중요한 작업을 병렬화시키기 어려워서 성능을 향상시킬 수 없을 때도 있다. 또한 프로세서 간의 중간 결과를 공유하는 비용이 병렬화로 인한 성능 향상보다 클 때도 있다.

이번 장에서는 스레드를 사용한 병렬화에 초점을 맞출 것이다. 분산 메모리 구조에서 병렬화와 관련된 문제, 예를 들어 클러스터 컴퓨팅과 같은 문제의 경우 지원자에게 코딩을 하라고 요구하지는 않는다. 보통은 설계와 관련된 문제로 출제된다. 문제 20.9, 문제 20.10, 문제 20.11, 문제 20.17의 경우에는 클러스터 레벨에서의 병렬화와 관련되어 있다.

## 병렬 컴퓨팅 부트 캠프

세마포어는 동기화를 구성할 때 굉장히 유용하다. 세마포어는, 일종의 '출입 허가' 집합을 유지하는 개념으로 생각하면 된다. 세마포어에서 acquire()를 호출하는 스레드는 허가를 받을 때까지 기다린 후에야 필요한 자원을 취득한다. 세마포어에서 release()를 호출하는 스레드는 허가를 반납한 뒤 해당 허가를 기다리고 있는 스레드들에게 통보함으로써, 결과적으로 대기하는 스레드가 계속해서 작업을 이어갈 수 있게 한다. 다음 프로그램은 동기화를 사용해서 Java에서의 세마포어, 즉 wait(), nofity()를 어떻게 구현하는지 보여준다. (Java에서는 세마포어의 모든 기능을 구현한 라이브러리를 제공하고 있고, 실제 업무에서도 사용할 수 있다.)

```java
public class Semaphore {
    private final int MAX_AVAILABLE;
    private int taken;

    public Semaphore(int maxAvailable) {
        this.MAX_AVAILABLE = maxAvailable;
        this.taken = 0;
    }

    public synchronized void acquire() throws InterruptedException {
        while (this.taken == MAX_AVAILABLE) {
            wait();
        }
        this.taken++;
    }

    public synchronized void release() throws InterruptedException {
        this.taken--;
        this.nofifyAll();
    }
}
```

## 동시성 문제를 풀기 전 꼭 알고 있어야 할 내용

- 먼저 **락을 적극적으로** 사용해서 알고리즘이 올바르게 작동하는지 쉽게 판단할 수 있도록 한다. 그 뒤 **중요한 공유 자원에 확실하게 락이 걸렸는지** 유의하면서 락을 **하나씩 제거**해 나간다. [문제 19.1, 19.6]
- 병렬화된 코드를 분석할 때는 언제나 최악의 상황을 생각하라. 예를 들어 같은 스레드를 반복해서 실행할 수도 있고, 두 스레드를 번갈아가며 실행할 수도 있고, 스레드가 고갈될 수도 있다. 이 모든 상황을 고려하라.
- **높은 추상화 수준**에서 작업하라. 특히 **병렬화 라이브러리**에 익숙해져야 한다. **세마포어, 스레드풀, 실행 지연시키기(deferred execution)**등은 직접 구현하지 말라. (이들을 어떻게 구현하는지는 알고 있어야 하고, 면접관이 요구하면 구현할 수 있어야 한다.) [문제 19.4]

