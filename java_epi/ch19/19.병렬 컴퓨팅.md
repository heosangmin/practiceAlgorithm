# 19장 병렬 컴퓨팅

```text
컴퓨터는 예측하지 못한 순간에 쏟아지는 다양한 메시지에 적절하게 반응해야 한다. 이런 상황은 여러 대의 컴퓨터가 서로 맞물려 있는 모든 정보 시스템에서 발생할 수 있다.
- <Cooperation sequential processes>, 에츠허르 데이크스트라(E. W. Dijkstra), 1965
```

병렬 컴퓨팅은 점차 많이 사용되고 있다. 노트북과 데스크톱에서는 이미 다중 프로세서가 공유 메모리를 통해 통신하고 있으며, 네트워크를 통해 통신하는 여러 컴퓨터의 집합인 클러스터는 복잡한 계산에 이용된다..

병렬화는 다음과 같은 장점이 있다.

- 고성능: 하나의 작업을 수행하는 프로세서가 많을수록 (보통) 작업을 더 빨리 끝낼 수 있다.
- 더 나은 리소스 이용: 프로그램을 수행하는 동안 다른 프로그램은 디스크나 네트워크를 기다릴 수 있다.
- 공정성: 하나의 프로그램만 돌아가는 것이 아니라, 동시간대에 다른 사용자나 프로그램이 하나의 컴퓨터를 공유한다.
- 편리성: 여러 프로그램이 동시에 부분 작업을 수행하는 것이 하나의 프로그램이 모든 부분 작업을 관리하는 것보다 개념적으로 더 간단할 수 있다.
- 실패 허용(fault tolerance): 웹 페이지를 보여 주는 컴퓨터가 어떤 클러스터 내에서 고장났을 때, 다른 컴퓨터가 이를 대신할 수 있다.

병렬 컴퓨팅의 실제 애플리케이션의 예제로는 그래픽 사용자 인터페이스(GUI)가 있다. 그래픽 사용자 인터페이스는 사용자 인터페이스를 담당하는 전담 스레드가 있다. 같은 시간에 다른 스레드는 네트워크 통신을 담당하거나 그 결과를 UI 스레드에 넘겨주는 역할을 한다. 이렇게 하면 반응성을 높일 수 있다. 또한 Java의 가상 머신(하나의 스레드가 사용자의 코드를 수행하는 동안 다른 스레드가 가비지 컬렉션을 수행한다), 웹 서버(하나의 논리적 스레드가 하나의 사용자의 요청을 담당한다), 과학적 수식 계산(커다란 행렬 곱셈은 여러 개의 컴퓨터로 나누어서 계산한다), 웹 검색(여러 컴퓨터가 웹문서를 긁어오고, 인덱스를 만들고, 결과를 사용자에게 반환한다) 등의 예제가 있다.

병렬 컴퓨팅의 두 가지 주요 모델은 프로세서가 같은 메모리 장소를 공유할 수 있는 메모리 공유 모델과 프로세서가 다른 프로세서에게 메시지를 명시적으로 보내야 하는 분산 메모리 모델이다. 메모리 공유 모델은 다중 코어의 경우에 더 적합하고 분산 메모리 모델은 클러스터의 경우에 더 적합하다. 이번 장의 문제는 공유 메모리 모델에 초점을 맞출 것이다.

병렬 프로그램을 올바르게 작성하는 것은 어려운 일이다. 왜냐하면 두 컴포넌트 간의 상호작용을 파악하기가 꽤 어렵기 때문이다. 그중에서도 경쟁(race) 문제가 가장 까다롭다. 경쟁이란 두 개의 명령이 동시에 같은 메모리 주소에 접근하고, 하나의 명령어가 무엇인가를 쓰려고(write) 하는 상황을 말한다. 병렬 프로그램을 올바르게 작성하기 어렵게 하는 요인들은 몇 가지가 더 있다.

- 고갈: 자원이 필요하지만 확보할 수 없을 때(문제 19.6)
- 데드락: A 스레드가 락 L1을 취득하고 B 스레드가 락 L2를 취득한 상태에서 A는 L2를 취득하려 하고, B는 L1을 취득하려 할 때
- 라이브락: 프로세서가 어떤 연산을 반복 실행하지만 계속 실패할 때

이러한 이유로 발생하는 버그는 테스트에서 찾기 어렵다. 또한 이러한 버그는 요청 패턴에 따라 달라질 수 있어서 재현하기 힘들기 때문에 디버깅도 어렵다. 그리고 병렬화에 따른 성능을 인지하기도 어렵다. 프로세서의 개수가 많아도 중요한 작업을 병렬화시키기 어려워서 성능을 향상시킬 수 없을 때도 있다. 또한 프로세서 간의 중간 결과를 공유하는 비용이 병렬화로 인한 성능 향상보다 클 때도 있다.

이번 장에서는 스레드를 사용한 병렬화에 초점을 맞출 것이다. 분산 메모리 구조에서 병렬화와 관련된 문제, 예를 들어 클러스터 컴퓨팅과 같은 문제의 경우 지원자에게 코딩을 하라고 요구하지는 않는다. 보통은 설계와 관련된 문제로 출제된다. 문제 20.9, 문제 20.10, 문제 20.11, 문제 20.17의 경우에는 클러스터 레벨에서의 병렬화와 관련되어 있다.

## 병렬 컴퓨팅 부트 캠프

세마포어는 동기화를 구성할 때 굉장히 유용하다. 세마포어는, 일종의 '출입 허가' 집합을 유지하는 개념으로 생각하면 된다. 세마포어에서 acquire()를 호출하는 스레드는 허가를 받을 때까지 기다린 후에야 필요한 자원을 취득한다. 세마포어에서 release()를 호출하는 스레드는 허가를 반납한 뒤 해당 허가를 기다리고 있는 스레드들에게 통보함으로써, 결과적으로 대기하는 스레드가 계속해서 작업을 이어갈 수 있게 한다. 다음 프로그램은 동기화를 사용해서 Java에서의 세마포어, 즉 wait(), nofity()를 어떻게 구현하는지 보여준다. (Java에서는 세마포어의 모든 기능을 구현한 라이브러리를 제공하고 있고, 실제 업무에서도 사용할 수 있다.)

```java
public class Semaphore {
    private final int MAX_AVAILABLE;
    private int taken;

    public Semaphore(int maxAvailable) {
        this.MAX_AVAILABLE = maxAvailable;
        this.taken = 0;
    }

    public synchronized void acquire() throws InterruptedException {
        while (this.taken == MAX_AVAILABLE) {
            wait();
        }
        this.taken++;
    }

    public synchronized void release() throws InterruptedException {
        this.taken--;
        this.nofifyAll();
    }
}
```

## 동시성 문제를 풀기 전 꼭 알고 있어야 할 내용

- 먼저 **락을 적극적으로** 사용해서 알고리즘이 올바르게 작동하는지 쉽게 판단할 수 있도록 한다. 그 뒤 **중요한 공유 자원에 확실하게 락이 걸렸는지** 유의하면서 락을 **하나씩 제거**해 나간다. [문제 19.1, 19.6]
- 병렬화된 코드를 분석할 때는 언제나 최악의 상황을 생각하라. 예를 들어 같은 스레드를 반복해서 실행할 수도 있고, 두 스레드를 번갈아가며 실행할 수도 있고, 스레드가 고갈될 수도 있다. 이 모든 상황을 고려하라.
- **높은 추상화 수준**에서 작업하라. 특히 **병렬화 라이브러리**에 익숙해져야 한다. **세마포어, 스레드풀, 실행 지연시키기(deferred execution)**등은 직접 구현하지 말라. (이들을 어떻게 구현하는지는 알고 있어야 하고, 면접관이 요구하면 구현할 수 있어야 한다.) [문제 19.4]

## 문제 191. 다중 스레드 사전을 위한 캐시 구현하기

다음은 실시간으로 오타를 정정해 주는 프로그램의 한 부분이다. 클라이언트가 문자열을 전송하면 사전에서 입력 문자열과 가장 가까운 문자열을 찾아 문자열 배열을 반환해야 한다. (이 배열은 문제 16.2의 해법을 사용해서 구할 수 있다.) 캐시를 사용해서 성능을 향상하려고 했지만 다음 코드에 문제점이 있다. 그 문제점을 찾고, 해결책을 제시하라.

```java
public static class UnsafeSpellCheckService extends SpellCheckService {
    private static final int MAX_ENTRIES = 3;

    private static LinkedHashMap<String, String[]> cachedClosestStrings
        = new LinkedHashMap<>() {
            protected boolean removeEldestEntry(Map.Entry eldest) {
                return size() > MAX_ENTRIES;
            }
        };
    
    public static void service(ServiceRequest req, ServiceResponse resp) {
        String w = req.extractWordToCheckFromRequest();
        if (cachedClosestStrings.containsKey(w)) {
            resp.encodeIntoResponse(cachedClosestStrings.get(w));
            return;
        }
        String[] closestToLastWord = Spell.closestInDictionary(w);
        cachedClosestStrings.put(w, closestToLastWord);
    }
}
```

> 힌트: 경쟁(race)이 발생하는 곳을 찾아보라. 그리고 처리량을 늘리기 위해 락을 최대한 적게 사용하라.

이 코드에는 경쟁 조건(race condition)이 존재한다. 클라이언트 A와 B가 각각 요청 A와 B를 동시에 요청하고, 각 요청을 담당하는 스레드가 하나씩 존재한다고 가정하자. 요청 A를 담당하는 스레드가 캐시에 입력 문자열이 존재한다는 사실을 발견한 뒤 스레드 B가 곧바로 실행됐다. 그리고 이 스레드는 캐시에서 문자열을 찾지 못해서 결과를 계산한 뒤 캐시에 넣는 작업을 한다. 만약 캐시가 꽉 찼다면 그중 하나를 버리는데, 그 엔트리가 요청 A가 원하는 엔트리일 수도 있다. 이제 요청 A를 담당하는 스레드가 다시 실행된다. 캐시에 입력 문자열이 존재한다고 알고 있었지만, 그 값을 읽으려고 하면 널(null)을 반환한다.

스레드-안전 해법은 앞의 서비스를 호출할 때마다 동기화를 하는 것이다. 이 경우에는 한 번에 하나의 스레드만 service() 메서드를 실행할 수 잇게 해서, 캐시를 읽을 때와 쓸 때 경쟁 조건이 없도록 한다. 하지만 한 번에 하나의 스레드만 실행된다면 전체 성능이 굉장히 안 좋을 것이다.

이럴 때는 꼭 필요한 부분에만 락을 설정하고 캐시 값을 사용하는 게 좋다. 캐시를 확인할 때와 캐시값을 갱신할 때만 락을 설정하는 것이다.

다음 프로그램은 다중 스레드가 동시에 가장 가까운 문자열들을 구하는 코드이다. 요청 처리에 걸리는 시간을 줄이기 위해 꼭 필요한 곳에만 락을 설정했다. 캐시를 사용하는 이유 역시 처리 시간을 줄이기 위해서다. 락을 사용하기 때문에 캐시를 읽거나 갱신하는 작업은 단일(atomic) 작업이 된다.

```java
public static class UnsafeSpellCheckService extends SpellCheckService {
    private static final int MAX_ENTRIES = 3;

    private static LinkedHashMap<String, String[]> cachedClosestStrings
        = new LinkedHashMap<>() {
            protected boolean removeEldestEntry(Map.Entry eldest) {
                return size() > MAX_ENTRIES;
            }
        };
    
    public static void service(ServiceRequest req, ServiceResponse resp) {
        String w = req.extractWordToCheckFromRequest();
        synchronized (S2Alternative.class) {
            if (cachedClosestStrings.containsKey(w)) {
                resp.encodeIntoResponse(cachedClosestStrings.get(w));
                return;
            }
        }
        String[] closestToLastWord = Spell.closestInDictionary(w);
        synchronized (S2Alternative.class) {
            cachedClosestStrings.put(w, closestToLastWord);
        }
    }
}
```

## 문제 19.2 두 개의 스레드가 동기화되지 않은 채 번갈아 수행되는 경우 분석하기

다음 코드에서 볼 수 있듯이 스레드 t1과 t2는 각각 정수값을 N번 증가시킨다. 하지만 이 프로그램의 결과는 일정하지 않다. 보통은 2N을 출력하지만 가끔 이보다 더 작은 값을 출력하기도 한다. N의 값이 커지면 이러한 현상이 더 자주 발생한다. 실제로 N = 1000000이 입력으로 주어졌을 때 1320209를 출력하는 경우도 있다.

```java
public static class IncrementThread implements Runnable {
    public void run() {
        for (int i = 0; i < TwoThreadIncrementDriver.N; i++) {
            TwoThreadIncrementDriver.counter++;
        }
    }
}

public static class TwoThreadIncrementDriver {
    public static int counter;
    public static int N;

    public static void main(String[] args) throws Exception {
        N = (args.length > 0) ? new Integer(args[0]) : 100;

        Thread t1 = new Thread(new IncrementThread());
        Thread t2 = new Thread(new IncrementThread());

        t1.start();
        t2.start();
        t1.join();
        t2.join();

        System.out.println(counter);
    }
}
```

N이 주어졌을 때 출력될 수 있는 최솟값과 최댓값은 무엇인가?

> 힌트: 스레드를 스케줄링할 때는 극단적인 경우를 생각하라.

먼저, 숫자를 증가시키는 부분이 락에 의해 보호받지 못하고 있으므로 스레드 스케줄러가 카운터를 증가시키는 스레드를 어떻게 배치시키느냐에 따라 그 값이 결정된다.

언제나 하나의 스레드가 끝난 뒤 다음 스레드가 실행된다면 이 프로그램이 출력할 수 있는 최댓값은 2N이다.

N = 1일 때, 출력될 수 있는 최솟값은 1이다. t1이 값을 읽고, t2가 값을 읽고, t1이 값을 증가한 뒤 갱신하고, t2가 값을 증가한 뒤 갱신하면 그렇게 된다. N > 1인 경우에 최종값은 적어도 2보다 크거나 같게 된다. 그 이유는 다음과 같이 두 가지 가능성이 존재한다. 첫 번째 가능성은 T1이 먼저 실행되는 경우다. T2라는 스레드가 값을 갱신하기 전에 스레드 T1이 읽고-증가하고-갱신하고-읽고-증가하고-갱신하는 작업을 수행한다면 그 결과는 적어도 2가 된다. 그다음 T2가 1을 쓰면, 아직 완료되지 않았으므로 적어도 한 번 더 증가한다. 두 번째 가능성은, T2가 먼저 실행되고 T1이 두 번째로 값을 읽는 경우다. 이때는 1 혹은 그 이상의 값을 읽는다. 왜냐하면 T2가 적어도 한번 값을 갱신했기 때문이다.

스레드가 다음과 같이 스케줄링될 때 가능한 최소한의 결괏값은 2가 된다.

- t1이 초깃값인 0을 읽는다.
- t2가 N - 1번 갱신 작업을 실행한다.
- t1은 그 사이에 값이 어떻게 바뀌었는지 모르므로 1로 갱신한다.
- t2가 최근에 갱신된 값인 1을 읽는다.
- t1이 N - 1번 갱신 작업을 실행한다.
- t2는 그 사이에 값이 어떻게 바뀌었는지 모르므로 2로 갱신한다.
