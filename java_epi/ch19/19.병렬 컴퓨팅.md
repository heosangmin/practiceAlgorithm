# 19장 병렬 컴퓨팅

```text
컴퓨터는 예측하지 못한 순간에 쏟아지는 다양한 메시지에 적절하게 반응해야 한다. 이런 상황은 여러 대의 컴퓨터가 서로 맞물려 있는 모든 정보 시스템에서 발생할 수 있다.
- <Cooperation sequential processes>, 에츠허르 데이크스트라(E. W. Dijkstra), 1965
```

병렬 컴퓨팅은 점차 많이 사용되고 있다. 노트북과 데스크톱에서는 이미 다중 프로세서가 공유 메모리를 통해 통신하고 있으며, 네트워크를 통해 통신하는 여러 컴퓨터의 집합인 클러스터는 복잡한 계산에 이용된다..

병렬화는 다음과 같은 장점이 있다.

- 고성능: 하나의 작업을 수행하는 프로세서가 많을수록 (보통) 작업을 더 빨리 끝낼 수 있다.
- 더 나은 리소스 이용: 프로그램을 수행하는 동안 다른 프로그램은 디스크나 네트워크를 기다릴 수 있다.
- 공정성: 하나의 프로그램만 돌아가는 것이 아니라, 동시간대에 다른 사용자나 프로그램이 하나의 컴퓨터를 공유한다.
- 편리성: 여러 프로그램이 동시에 부분 작업을 수행하는 것이 하나의 프로그램이 모든 부분 작업을 관리하는 것보다 개념적으로 더 간단할 수 있다.
- 실패 허용(fault tolerance): 웹 페이지를 보여 주는 컴퓨터가 어떤 클러스터 내에서 고장났을 때, 다른 컴퓨터가 이를 대신할 수 있다.

병렬 컴퓨팅의 실제 애플리케이션의 예제로는 그래픽 사용자 인터페이스(GUI)가 있다. 그래픽 사용자 인터페이스는 사용자 인터페이스를 담당하는 전담 스레드가 있다. 같은 시간에 다른 스레드는 네트워크 통신을 담당하거나 그 결과를 UI 스레드에 넘겨주는 역할을 한다. 이렇게 하면 반응성을 높일 수 있다. 또한 Java의 가상 머신(하나의 스레드가 사용자의 코드를 수행하는 동안 다른 스레드가 가비지 컬렉션을 수행한다), 웹 서버(하나의 논리적 스레드가 하나의 사용자의 요청을 담당한다), 과학적 수식 계산(커다란 행렬 곱셈은 여러 개의 컴퓨터로 나누어서 계산한다), 웹 검색(여러 컴퓨터가 웹문서를 긁어오고, 인덱스를 만들고, 결과를 사용자에게 반환한다) 등의 예제가 있다.

병렬 컴퓨팅의 두 가지 주요 모델은 프로세서가 같은 메모리 장소를 공유할 수 있는 메모리 공유 모델과 프로세서가 다른 프로세서에게 메시지를 명시적으로 보내야 하는 분산 메모리 모델이다. 메모리 공유 모델은 다중 코어의 경우에 더 적합하고 분산 메모리 모델은 클러스터의 경우에 더 적합하다. 이번 장의 문제는 공유 메모리 모델에 초점을 맞출 것이다.

병렬 프로그램을 올바르게 작성하는 것은 어려운 일이다. 왜냐하면 두 컴포넌트 간의 상호작용을 파악하기가 꽤 어렵기 때문이다. 그중에서도 경쟁(race) 문제가 가장 까다롭다. 경쟁이란 두 개의 명령이 동시에 같은 메모리 주소에 접근하고, 하나의 명령어가 무엇인가를 쓰려고(write) 하는 상황을 말한다. 병렬 프로그램을 올바르게 작성하기 어렵게 하는 요인들은 몇 가지가 더 있다.

- 고갈: 자원이 필요하지만 확보할 수 없을 때(문제 19.6)
- 데드락: A 스레드가 락 L1을 취득하고 B 스레드가 락 L2를 취득한 상태에서 A는 L2를 취득하려 하고, B는 L1을 취득하려 할 때
- 라이브락: 프로세서가 어떤 연산을 반복 실행하지만 계속 실패할 때

이러한 이유로 발생하는 버그는 테스트에서 찾기 어렵다. 또한 이러한 버그는 요청 패턴에 따라 달라질 수 있어서 재현하기 힘들기 때문에 디버깅도 어렵다. 그리고 병렬화에 따른 성능을 인지하기도 어렵다. 프로세서의 개수가 많아도 중요한 작업을 병렬화시키기 어려워서 성능을 향상시킬 수 없을 때도 있다. 또한 프로세서 간의 중간 결과를 공유하는 비용이 병렬화로 인한 성능 향상보다 클 때도 있다.

이번 장에서는 스레드를 사용한 병렬화에 초점을 맞출 것이다. 분산 메모리 구조에서 병렬화와 관련된 문제, 예를 들어 클러스터 컴퓨팅과 같은 문제의 경우 지원자에게 코딩을 하라고 요구하지는 않는다. 보통은 설계와 관련된 문제로 출제된다. 문제 20.9, 문제 20.10, 문제 20.11, 문제 20.17의 경우에는 클러스터 레벨에서의 병렬화와 관련되어 있다.

## 병렬 컴퓨팅 부트 캠프

세마포어는 동기화를 구성할 때 굉장히 유용하다. 세마포어는, 일종의 '출입 허가' 집합을 유지하는 개념으로 생각하면 된다. 세마포어에서 acquire()를 호출하는 스레드는 허가를 받을 때까지 기다린 후에야 필요한 자원을 취득한다. 세마포어에서 release()를 호출하는 스레드는 허가를 반납한 뒤 해당 허가를 기다리고 있는 스레드들에게 통보함으로써, 결과적으로 대기하는 스레드가 계속해서 작업을 이어갈 수 있게 한다. 다음 프로그램은 동기화를 사용해서 Java에서의 세마포어, 즉 wait(), nofity()를 어떻게 구현하는지 보여준다. (Java에서는 세마포어의 모든 기능을 구현한 라이브러리를 제공하고 있고, 실제 업무에서도 사용할 수 있다.)

```java
public class Semaphore {
    private final int MAX_AVAILABLE;
    private int taken;

    public Semaphore(int maxAvailable) {
        this.MAX_AVAILABLE = maxAvailable;
        this.taken = 0;
    }

    public synchronized void acquire() throws InterruptedException {
        while (this.taken == MAX_AVAILABLE) {
            wait();
        }
        this.taken++;
    }

    public synchronized void release() throws InterruptedException {
        this.taken--;
        this.nofifyAll();
    }
}
```

## 동시성 문제를 풀기 전 꼭 알고 있어야 할 내용

- 먼저 **락을 적극적으로** 사용해서 알고리즘이 올바르게 작동하는지 쉽게 판단할 수 있도록 한다. 그 뒤 **중요한 공유 자원에 확실하게 락이 걸렸는지** 유의하면서 락을 **하나씩 제거**해 나간다. [문제 19.1, 19.6]
- 병렬화된 코드를 분석할 때는 언제나 최악의 상황을 생각하라. 예를 들어 같은 스레드를 반복해서 실행할 수도 있고, 두 스레드를 번갈아가며 실행할 수도 있고, 스레드가 고갈될 수도 있다. 이 모든 상황을 고려하라.
- **높은 추상화 수준**에서 작업하라. 특히 **병렬화 라이브러리**에 익숙해져야 한다. **세마포어, 스레드풀, 실행 지연시키기(deferred execution)**등은 직접 구현하지 말라. (이들을 어떻게 구현하는지는 알고 있어야 하고, 면접관이 요구하면 구현할 수 있어야 한다.) [문제 19.4]

## 문제 19.1 다중 스레드 사전을 위한 캐시 구현하기

다음은 실시간으로 오타를 정정해 주는 프로그램의 한 부분이다. 클라이언트가 문자열을 전송하면 사전에서 입력 문자열과 가장 가까운 문자열을 찾아 문자열 배열을 반환해야 한다. (이 배열은 문제 16.2의 해법을 사용해서 구할 수 있다.) 캐시를 사용해서 성능을 향상하려고 했지만 다음 코드에 문제점이 있다. 그 문제점을 찾고, 해결책을 제시하라.

```java
public static class UnsafeSpellCheckService extends SpellCheckService {
    private static final int MAX_ENTRIES = 3;

    private static LinkedHashMap<String, String[]> cachedClosestStrings
        = new LinkedHashMap<>() {
            protected boolean removeEldestEntry(Map.Entry eldest) {
                return size() > MAX_ENTRIES;
            }
        };
    
    public static void service(ServiceRequest req, ServiceResponse resp) {
        String w = req.extractWordToCheckFromRequest();
        if (cachedClosestStrings.containsKey(w)) {
            resp.encodeIntoResponse(cachedClosestStrings.get(w));
            return;
        }
        String[] closestToLastWord = Spell.closestInDictionary(w);
        cachedClosestStrings.put(w, closestToLastWord);
    }
}
```

> 힌트: 경쟁(race)이 발생하는 곳을 찾아보라. 그리고 처리량을 늘리기 위해 락을 최대한 적게 사용하라.

이 코드에는 경쟁 조건(race condition)이 존재한다. 클라이언트 A와 B가 각각 요청 A와 B를 동시에 요청하고, 각 요청을 담당하는 스레드가 하나씩 존재한다고 가정하자. 요청 A를 담당하는 스레드가 캐시에 입력 문자열이 존재한다는 사실을 발견한 뒤 스레드 B가 곧바로 실행됐다. 그리고 이 스레드는 캐시에서 문자열을 찾지 못해서 결과를 계산한 뒤 캐시에 넣는 작업을 한다. 만약 캐시가 꽉 찼다면 그중 하나를 버리는데, 그 엔트리가 요청 A가 원하는 엔트리일 수도 있다. 이제 요청 A를 담당하는 스레드가 다시 실행된다. 캐시에 입력 문자열이 존재한다고 알고 있었지만, 그 값을 읽으려고 하면 널(null)을 반환한다.

스레드-안전 해법은 앞의 서비스를 호출할 때마다 동기화를 하는 것이다. 이 경우에는 한 번에 하나의 스레드만 service() 메서드를 실행할 수 잇게 해서, 캐시를 읽을 때와 쓸 때 경쟁 조건이 없도록 한다. 하지만 한 번에 하나의 스레드만 실행된다면 전체 성능이 굉장히 안 좋을 것이다.

이럴 때는 꼭 필요한 부분에만 락을 설정하고 캐시 값을 사용하는 게 좋다. 캐시를 확인할 때와 캐시값을 갱신할 때만 락을 설정하는 것이다.

다음 프로그램은 다중 스레드가 동시에 가장 가까운 문자열들을 구하는 코드이다. 요청 처리에 걸리는 시간을 줄이기 위해 꼭 필요한 곳에만 락을 설정했다. 캐시를 사용하는 이유 역시 처리 시간을 줄이기 위해서다. 락을 사용하기 때문에 캐시를 읽거나 갱신하는 작업은 단일(atomic) 작업이 된다.

```java
public static class UnsafeSpellCheckService extends SpellCheckService {
    private static final int MAX_ENTRIES = 3;

    private static LinkedHashMap<String, String[]> cachedClosestStrings
        = new LinkedHashMap<>() {
            protected boolean removeEldestEntry(Map.Entry eldest) {
                return size() > MAX_ENTRIES;
            }
        };
    
    public static void service(ServiceRequest req, ServiceResponse resp) {
        String w = req.extractWordToCheckFromRequest();
        synchronized (S2Alternative.class) {
            if (cachedClosestStrings.containsKey(w)) {
                resp.encodeIntoResponse(cachedClosestStrings.get(w));
                return;
            }
        }
        String[] closestToLastWord = Spell.closestInDictionary(w);
        synchronized (S2Alternative.class) {
            cachedClosestStrings.put(w, closestToLastWord);
        }
    }
}
```

## 문제 19.2 두 개의 스레드가 동기화되지 않은 채 번갈아 수행되는 경우 분석하기

다음 코드에서 볼 수 있듯이 스레드 t1과 t2는 각각 정수값을 N번 증가시킨다. 하지만 이 프로그램의 결과는 일정하지 않다. 보통은 2N을 출력하지만 가끔 이보다 더 작은 값을 출력하기도 한다. N의 값이 커지면 이러한 현상이 더 자주 발생한다. 실제로 N = 1000000이 입력으로 주어졌을 때 1320209를 출력하는 경우도 있다.

```java
public static class IncrementThread implements Runnable {
    public void run() {
        for (int i = 0; i < TwoThreadIncrementDriver.N; i++) {
            TwoThreadIncrementDriver.counter++;
        }
    }
}

public static class TwoThreadIncrementDriver {
    public static int counter;
    public static int N;

    public static void main(String[] args) throws Exception {
        N = (args.length > 0) ? new Integer(args[0]) : 100;

        Thread t1 = new Thread(new IncrementThread());
        Thread t2 = new Thread(new IncrementThread());

        t1.start();
        t2.start();
        t1.join();
        t2.join();

        System.out.println(counter);
    }
}
```

N이 주어졌을 때 출력될 수 있는 최솟값과 최댓값은 무엇인가?

> 힌트: 스레드를 스케줄링할 때는 극단적인 경우를 생각하라.

먼저, 숫자를 증가시키는 부분이 락에 의해 보호받지 못하고 있으므로 스레드 스케줄러가 카운터를 증가시키는 스레드를 어떻게 배치시키느냐에 따라 그 값이 결정된다.

언제나 하나의 스레드가 끝난 뒤 다음 스레드가 실행된다면 이 프로그램이 출력할 수 있는 최댓값은 2N이다.

N = 1일 때, 출력될 수 있는 최솟값은 1이다. t1이 값을 읽고, t2가 값을 읽고, t1이 값을 증가한 뒤 갱신하고, t2가 값을 증가한 뒤 갱신하면 그렇게 된다. N > 1인 경우에 최종값은 적어도 2보다 크거나 같게 된다. 그 이유는 다음과 같이 두 가지 가능성이 존재한다. 첫 번째 가능성은 T1이 먼저 실행되는 경우다. T2라는 스레드가 값을 갱신하기 전에 스레드 T1이 읽고-증가하고-갱신하고-읽고-증가하고-갱신하는 작업을 수행한다면 그 결과는 적어도 2가 된다. 그다음 T2가 1을 쓰면, 아직 완료되지 않았으므로 적어도 한 번 더 증가한다. 두 번째 가능성은, T2가 먼저 실행되고 T1이 두 번째로 값을 읽는 경우다. 이때는 1 혹은 그 이상의 값을 읽는다. 왜냐하면 T2가 적어도 한번 값을 갱신했기 때문이다.

스레드가 다음과 같이 스케줄링될 때 가능한 최소한의 결괏값은 2가 된다.

- t1이 초깃값인 0을 읽는다.
- t2가 N - 1번 갱신 작업을 실행한다.
- t1은 그 사이에 값이 어떻게 바뀌었는지 모르므로 1로 갱신한다.
- t2가 최근에 갱신된 값인 1을 읽는다.
- t1이 N - 1번 갱신 작업을 실행한다.
- t2는 그 사이에 값이 어떻게 바뀌었는지 모르므로 2로 갱신한다.

## 문제 19.3 두 개의 스레드가 번갈아 수행될 때 동기화 구현하기

스레드 t1은 1부터 100까지의 홀수를 출력한다. 스레드 t2는 1에서 100까지의 짝수를 출력한다. 두 개의 스레드가 동시에 수행될 때 1부터 100까지 차례대로 출력하는 코드를 작성하라.

> 힌트: 두 개의 스레드가 작업이 끝나면 서로에게 알려 줘야 한다.

무식한 방법은 두 개의 스레드가 번갈아 가며 락을 사용하는 것이다. 락을 사용해서 현재 어떤 스레드가 변수를 출력할 차례인지 확인을 한다. 그러나 이 방법은 프로세서가 다른 작업을 처리하는 데 쓸 수 있는 시간을 낭비하는 바쁜 대기(busy waiting)를 사용한다.

다음은 이 아이디어를 코드로 구현하되 java의 wait()와 notify()를 사용해서 바쁜 대기를 회피하는 것이다.

```java
public static class OddEvenMonitor {
    public static final boolean ODD_TURN = true;
    public static final boolean EVEN_TURN = false;
    private boolean turn = ODD_TURN;

    // wait()를 호출하기 위해선 동기화 작업이 필요하다.
    // 자세한 설명은 링크를 참조하라: https://stackoverflow.com/questions/2779484
    public synchronized void waitTurn(boolean oldTurn) {
        while (turn != oldTurn) {
            try {
                wait();
            } catch (InterruptedException e) {
                System.out.println("InterruptedException in wait(): " + e);
            }
        }
        // 우리가 실행할 차례이다.
    }

    // notify()를 실행하기 위해선 동기화 작업이 필요하다.
    public synchronized void toggleTurn() {
        turn ^= true;
        notify();
    }
}

public static class OddThread extends Thread {
    private final OddEvenMonitor monitor;

    public OddThread(OddEvenMonitor monitor) { this.monitor = monitor; }
    @Override
    public void run() {
        for (int i = 1; i <= 100; i += 2) {
            monitor.waitTurn(OddEvenMonitor.ODD_TURN);
            System.out.println("i = " + i);
            monitor.toggleTurn();
        }
    }
}

public static class EvenThread extends Thread {
    private final OddEvenMonitor monitor;

    public EvenThread(OddEvenMonitor monitor) { this.monitor = monitor; }
    @Override
    public void run() {
        for (int i = 2; i <= 100; i += 2) {
            monitor.waitTurn(OddEvenMonitor.EVEN_TURN);
            System.out.println("i = " + i);
            monitor.toggleTurn();
        }
    }
}

public static void main(String[] args) throws InterruptedException {
    OddEvenMonitor monitor = new OddEvenMonitor();
    Thread t1 = new OddThread(monitor);
    Thread t2 = new EvenThread(monitor);
    t1.start();
    t2.start();
    t1.join();
    t2.join();
}
```

## 문제 19.4 스레드 풀 구현하기

다음 프로그램은 간단한 HTTP 서버를 구현한 코드이다.

```java
public static class SingleThreadWebServer {
    public static final int PORT = 8080;
    public static void main(String[] args) throws IOException {
        ServerSocket serversock = new ServerSocket(PORT);
        for (;;) {
            Socket sock = serversock.accept();
            processReq(sock);
        }
    }
}
```

이 프로그램이 I/O를 자주 차단해서 성능이 굉장히 나쁘다고 가정하자. 어떻게 하면 프로그램의 성능을 향상시킬 수 있을까? 동기화 클래스를 포함해서 표준 라이브러리는 얼마든지 사용해도 좋다.

> 힌트: 다중 스레드를 사용하라. 단, 스레드의 개수를 무한정 늘려서는 안 된다.

가장 먼저 할 수 있는 작업은 요청을 직접 처리하기보다 각 요청을 담당하는 새로운 스레드를 만드는 것이다.

```java
public static class ConcurrentWebServer {
    private static final int SERVERPORT = 8080;
    public static void main(String[] args) throws IOException {
        final ServerSocket serversocket = new ServerSocket(SERVERPORT);
        while (true) {
            final Socket connection = serversocket.accept();
            Runnable task = new Runnable() {
                public void run() { Worker.handleRequest(connection); }
            };
            new Thread(task).start();
        }
    }
}
```

이 방법의 문제는 스레드의 개수를 직접 조절할 수 없다는 점이다. 각 스레드는 꽤 많은 양의 자원을 사용한다. 스레드를 시작하거나 끝낼 때 필요한 시간과 각 스레드가 사용하는 메모리 공간이 매우 많이 필요하다. 요청이 많지 않은 서버일 경우에는 문제가 되지 않을 수 있지만, 요청의 개수가 많아지면 처리하기 어려운 예외가 발생할 수 있다.

이를 보완하기 위해 스레드 풀을 사용한다. 이름에서 알 수 있듯이 처음에 스레드의 개수를 한정한 뒤 그만큼의 컬렉션을 사용한다. 블록 큐(blocking queue)를 사용하면 상대적으로 쉽게 스레드 풀을 구현할 수 있다. 블록 큐란 큐가 비어 있는 상태가 될 때까지 스레드의 갱신 작업을 블록하는 것을 말한다. 하지만 문제에서 명시적으로 라이브러리를 사용해도 된다고 했기 때문에 여기서는 Executor 프레임워크에서 제공하는 스레드 풀을 사용할 것이다. 다음은 이를 구현한 코드이다.

```java
public static class ThreadPoolWebServer {
    private static final int NTHREAD = 100;
    private static final int SERVERPORT = 8080;
    private static final Executor exec = Executors.newFixedThreadPool(NTHREAD);

    public static void main(String[] args) throws IOException {
        ServerSocket serversocket = new ServerSocket(SERVERPORT);
        while (true) {
            final Socket connection = serversocket.accept();
            Runnable task = new Runnable() {
                public void run() { Worker.handleRequest(connection); }
            };
            exec.execute(task);
        }
    }
}
```

## 문제 19.5 데드락 피하기

어떤 작업을 수행하기 위해서 스레드가 여러 개의 락을 취득해야 한다면 데드락이 발생할 가능성이 있다. 예를 들어 T1과 T2가 모두 L과 M을 취득해야 한다고 하자. T1이 먼저 L을 취득하고 T2가 그 다음에 M을 취득한다면 이 둘은 영원히 상대방을 기다리게 된다.

다음 프로그램에서 이와 같은 버그를 찾은 뒤 코드를 수정해서 그 문제를 해결하라.

```java
public static class Account {
    private int balance;
    private int id;
    private static int globalId;

    Account(int balance) {
        this.balance = balance;
        this.id = ++globalId;
    }

    private boolean move(Account to, int amount) {
        synchronized (this) {
            synchronized (to) {
                if (amount > balance) {
                    return false;
                }
                to.balance += amount;
                this.balance -= amount;
                System.out.println("returning true");
                return true;
            }
        }
    }

    public static void transfer(final Account from, final Account to, final int amount) {
        Thread transfer = new Thread(new Runnable() {
            public void run() { from.move(to, amount); }
        });
        transfer.start();
    }
}
```

U1에서 U2로의 송금 바로 직후에 U2에서 U1으로 송금한다고 가정해 보자. 각 송금은 서로 다른 스레드가 담당하기 때문에 첫 번째 스레드가 U1에 락을 건 뒤 두 번째 스레드가 실행돼서 U2에 락을 걸 수도 있다. 그러면 이 프로그램은 데드락 상태에 빠지게 된다. 결국 두 스레드는 모두 다른 스레드가 락을 해제하기를 기다리게 된다.

한 가지 가능한 해법은 송금을 할 때 전역으로 정의된 락을 사용하는 것이다. 이 방법의 단점은 아무 관련 없는 다른 송금에 대해서도 모두 블록하게 된다는 점이다. 즉, U5에서 U6으로 송금할 때 U3에서 U4로 송금할 수 없다.

데드락을 피할 수 있는 다른 방법은 락을 취득할 때 전역적인 순서대로 취득하게 하면 된다. 각 계좌에 유일한 ID가 부여되므로 다음과 같이 수정하면 데드락을 피할 수 있다.

```java
Account lock1 = (id < to.id) ? this : to;
Account lock2 = (id < to.id) ? to : this;
synchronized (lock1) {
    // lock1과 lock2가 같아도 된다.
    // Java에서 락은 재진입이 가능하므로 lock2를 다시 취득하기 때문이다.
    synchronized (lock2) {
        ...
    }
}
```